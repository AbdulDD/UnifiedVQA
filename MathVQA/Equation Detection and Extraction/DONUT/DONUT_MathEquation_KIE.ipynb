{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e0aee3556fc4359b0946c17137d1208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c4b0e3efbe1410a98ca1dc597daeb5e",
              "IPY_MODEL_a25295bf9a6a4a8b86616f63d121d4f2",
              "IPY_MODEL_8e5bbb0d5c0c428d9a4482493ea4cbe3"
            ],
            "layout": "IPY_MODEL_b4443680e837470595f8c2d8f73483ce",
            "tabbable": null,
            "tooltip": null
          }
        },
        "0c4b0e3efbe1410a98ca1dc597daeb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_65e0d876cb864c53a8595dd10caf9c43",
            "placeholder": "​",
            "style": "IPY_MODEL_6f6d8575d6524a1883b9109933f05ed5",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "a25295bf9a6a4a8b86616f63d121d4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bde16eb4f33049dc96a09eed14187b8d",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a05248cbe4714c85967bb79f1f869c82",
            "tabbable": null,
            "tooltip": null,
            "value": 239
          }
        },
        "8e5bbb0d5c0c428d9a4482493ea4cbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_20254f0f4d53495d989f0e94c7efea2b",
            "placeholder": "​",
            "style": "IPY_MODEL_c44c291856ab45da9d78fead54ff5ae5",
            "tabbable": null,
            "tooltip": null,
            "value": " 239/239 [03:27&lt;00:00,  1.16 examples/s]"
          }
        },
        "b4443680e837470595f8c2d8f73483ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e0d876cb864c53a8595dd10caf9c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6d8575d6524a1883b9109933f05ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "bde16eb4f33049dc96a09eed14187b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a05248cbe4714c85967bb79f1f869c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20254f0f4d53495d989f0e94c7efea2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c44c291856ab45da9d78fead54ff5ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "5f8db19bb9a045639e4e406867263ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_961f989979ad457ab0975e19b390facc",
              "IPY_MODEL_cd54a8d7a5cb458cadb2ad669ae0a641",
              "IPY_MODEL_619ecc98df3348a88e20ae4b57cbfc76"
            ],
            "layout": "IPY_MODEL_dc8596e903e5453a9ddb187e2f0aab9d",
            "tabbable": null,
            "tooltip": null
          }
        },
        "961f989979ad457ab0975e19b390facc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_96afd9f46c1c48b9b7ae0329a02e1492",
            "placeholder": "​",
            "style": "IPY_MODEL_f88be70ab56e4a73b8d1058e950d6a6b",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "cd54a8d7a5cb458cadb2ad669ae0a641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4bc808865161450c8d96412d7c6074d3",
            "max": 839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a204008e16b4c9d9ea0a81582c71736",
            "tabbable": null,
            "tooltip": null,
            "value": 839
          }
        },
        "619ecc98df3348a88e20ae4b57cbfc76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_14fab2db3e704fa4825e5c8048a330eb",
            "placeholder": "​",
            "style": "IPY_MODEL_96bb099683d843e58687f178af95c528",
            "tabbable": null,
            "tooltip": null,
            "value": " 839/839 [12:29&lt;00:00,  1.12 examples/s]"
          }
        },
        "dc8596e903e5453a9ddb187e2f0aab9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96afd9f46c1c48b9b7ae0329a02e1492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f88be70ab56e4a73b8d1058e950d6a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4bc808865161450c8d96412d7c6074d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a204008e16b4c9d9ea0a81582c71736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14fab2db3e704fa4825e5c8048a330eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96bb099683d843e58687f178af95c528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nwTXkKRPtq4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU setup\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J_TovycQD0V",
        "outputId": "4fe3a17c-8712-45ae-b23b-ff277c90acdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "processor = DonutProcessor.from_pretrained(r'E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\checkpoint-800')"
      ],
      "metadata": {
        "id": "fMa62ZP7R_vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = VisionEncoderDecoderModel.from_pretrained(r'naver-clova-ix/donut-base')\n",
        "# model.save_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\model_save_dirctory\\LieghtModel\",)"
      ],
      "metadata": {
        "id": "t5T87Bz2Q97Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = VisionEncoderDecoderModel.from_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\checkpoint-2200\")\n",
        "# model.to(device)\n",
        "\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\checkpoint-2200\")\n",
        "model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "r1YSeuX0ZZqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d6a07f-3d3c-4f0c-8c49-b5c0b889c60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.donut.modeling_donut_swin.DonutSwinModel'> is overwritten by shared encoder config: DonutSwinConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"depths\": [\n",
            "    2,\n",
            "    2,\n",
            "    14,\n",
            "    2\n",
            "  ],\n",
            "  \"drop_path_rate\": 0.1,\n",
            "  \"embed_dim\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"image_size\": [\n",
            "    720,\n",
            "    960\n",
            "  ],\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"mlp_ratio\": 4.0,\n",
            "  \"model_type\": \"donut-swin\",\n",
            "  \"num_channels\": 3,\n",
            "  \"num_heads\": [\n",
            "    4,\n",
            "    8,\n",
            "    16,\n",
            "    32\n",
            "  ],\n",
            "  \"num_layers\": 4,\n",
            "  \"patch_size\": 4,\n",
            "  \"path_norm\": true,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_absolute_embeddings\": false,\n",
            "  \"window_size\": 10\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.mbart.modeling_mbart.MBartForCausalLM'> is overwritten by shared decoder config: MBartConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 4,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 1536,\n",
            "  \"model_type\": \"mbart\",\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": true,\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 57541\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionEncoderDecoderModel(\n",
              "  (encoder): DonutSwinModel(\n",
              "    (embeddings): DonutSwinEmbeddings(\n",
              "      (patch_embeddings): DonutSwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): DonutSwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-13): 14 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (decoder): MBartForCausalLM(\n",
              "    (model): MBartDecoderWrapper(\n",
              "      (decoder): MBartDecoder(\n",
              "        (embed_tokens): MBartScaledWordEmbedding(57541, 1024, padding_idx=1)\n",
              "        (embed_positions): MBartLearnedPositionalEmbedding(1538, 1024)\n",
              "        (layers): ModuleList(\n",
              "          (0-3): 4 x MBartDecoderLayer(\n",
              "            (self_attn): MBartSdpaAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (activation_fn): GELUActivation()\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (encoder_attn): MBartSdpaAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (lm_head): Linear(in_features=1024, out_features=57541, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY5a_y_sKSil",
        "outputId": "5088b1d7-a727-43bd-8c9f-7f43e5b226e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201868408"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "KuJebZo9E0Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "dataset = load_from_disk(r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\generated_dataset\\processed_dataset\")\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZiuDQXaiP5b",
        "outputId": "ec89ceb2-df25-4f70-a055-f1e868830c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'text'],\n",
              "        num_rows: 839\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['image', 'text'],\n",
              "        num_rows: 239\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "\n",
        "# def fill_missing_keys(json_file_path):\n",
        "#     # Open and read the JSON file\n",
        "#     with open(json_file_path, 'r') as f:\n",
        "#         data = json.load(f)\n",
        "\n",
        "#     # Define the expected keys\n",
        "#     expected_keys = [f'latex_{i}' for i in range(10)]\n",
        "\n",
        "#     # Check for missing keys and fill them with 'None' if necessary\n",
        "#     for key in expected_keys:\n",
        "#         if key not in data:\n",
        "#             data[key] = 'None'  # Add the key with the value 'None'\n",
        "\n",
        "#     # Save the updated data back to the JSON file\n",
        "#     with open(json_file_path, 'w') as f:\n",
        "#         json.dump(data, f, indent=4)\n",
        "\n",
        "# def process_json_files_in_folder(folder_path):\n",
        "#     # Iterate over all files in the specified folder\n",
        "#     for filename in os.listdir(folder_path):\n",
        "#         if filename.endswith('.json'):\n",
        "#             json_file_path = os.path.join(folder_path, filename)\n",
        "#             fill_missing_keys(json_file_path)\n",
        "#             print(f'Filled missing keys in {filename}')\n",
        "\n",
        "# # Specify the folder containing the JSON files\n",
        "# folder_A =r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex4\\train/A\"  # Replace with the actual path to folder A\n",
        "\n",
        "# # Process the JSON files\n",
        "# process_json_files_in_folder(folder_A)\n"
      ],
      "metadata": {
        "id": "UpvAsLt7_TLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90U-fpBe_TI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "# import pandas as pd\n",
        "# from PIL import Image\n",
        "# from datasets import Dataset, DatasetDict\n",
        "\n",
        "# # Specify the path to your validation image folder and JSON files folder\n",
        "# image_folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex4\\valid/images\"\n",
        "# json_folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex4\\valid/A\"\n",
        "\n",
        "# # List all image file paths and corresponding JSON files in the folders\n",
        "# image_files = [os.path.join(image_folder_path, image_file) for image_file in os.listdir(image_folder_path) if image_file.endswith('.jpg')]\n",
        "# json_files = [os.path.join(json_folder_path, json_file) for json_file in os.listdir(json_folder_path) if json_file.endswith('.json')]\n",
        "\n",
        "# # Initialize lists to store image paths and corresponding ground truth\n",
        "# valid_images = []\n",
        "# valid_gt = []\n",
        "\n",
        "# # Read each JSON file and extract information in the new format\n",
        "# for image_file in image_files:\n",
        "#     json_file = os.path.join(json_folder_path, os.path.splitext(os.path.basename(image_file))[0] + '.json')\n",
        "#     if os.path.exists(json_file):\n",
        "#         with open(json_file, 'r') as f:\n",
        "#             data = json.load(f)\n",
        "\n",
        "#             # Convert JSON directly to the expected format\n",
        "#             latex_dict = {key: value for key, value in data.items() if key.startswith(\"latex_\")}\n",
        "\n",
        "#             # Append the modified dictionary to valid_gt\n",
        "#             valid_images.append(Image.open(image_file))\n",
        "#             valid_gt.append(latex_dict)\n",
        "\n",
        "# # Create a dictionary with keys 'image' and 'text' for the validation split\n",
        "# valid_data = {'image': valid_images, 'text': valid_gt}\n",
        "\n",
        "# import os\n",
        "# import json\n",
        "# from PIL import Image\n",
        "\n",
        "# # Specify the path to your training image and JSON folders\n",
        "# image_folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex4\\train/images\"\n",
        "# json_folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex4\\train/A\"\n",
        "\n",
        "# # List all image file paths and corresponding JSON files in the folders\n",
        "# image_files = [os.path.join(image_folder_path, image_file) for image_file in os.listdir(image_folder_path) if image_file.endswith('.jpg')]\n",
        "# json_files = [os.path.join(json_folder_path, json_file) for json_file in os.listdir(json_folder_path) if json_file.endswith('.json')]\n",
        "\n",
        "# # Initialize lists to store image paths and corresponding ground truth\n",
        "# train_images = []\n",
        "# train_gt = []\n",
        "\n",
        "# # Read each JSON file and extract information in the required format\n",
        "# for image_file in image_files:\n",
        "#     json_file = os.path.join(json_folder_path, os.path.splitext(os.path.basename(image_file))[0] + '.json')\n",
        "#     if os.path.exists(json_file):\n",
        "#         with open(json_file, 'r') as f:\n",
        "#             data = json.load(f)\n",
        "#             print(data)\n",
        "\n",
        "#             data = {**data}\n",
        "\n",
        "#             # Convert JSON directly to the expected format\n",
        "#             latex_dict = {key: value for key, value in data.items() if key.startswith(\"latex_\") and value is not None}\n",
        "\n",
        "#             print(latex_dict)\n",
        "\n",
        "#             # Append the modified dictionary to train_gt\n",
        "#             train_images.append(Image.open(image_file))\n",
        "#             train_gt.append(latex_dict)\n",
        "\n",
        "# # Create a dictionary with keys 'image' and 'text' for the training split{'latex_1': 'D : S \\\\rightarrow S + \\\\lambda ,', 'latex_2': '\\\\hat { \\\\nabla } _ { m } \\\\tilde { \\\\eta } = 0 .', 'latex_3': 'E = e \\\\lparen 1 + 4 \\\\theta _ { 1 } e \\\\rparen ,', 'latex_4': 'z = \\\\cos ^ { 2 } \\\\frac { \\\\mu } { 2 R } .', 'latex_5': '\\\\bar { \\\\Delta } U = 0 = \\\\bar { U } \\\\Delta ,', 'latex_6': '\\\\ln \\\\omega _ { \\\\alpha } = \\\\ln \\\\omega _ { \\\\beta } .', 'latex_7': '\\\\delta _ { \\\\omega } I \\\\lbrack \\\\theta \\\\rbrack = 0 ,', 'latex_8': 'v \\\\lambda + x y = 0 , v + x u \\\\rho ^ { 2 } = 0 .'}\n",
        "\n",
        "# train_data = {'image': train_images, 'text': train_gt}\n",
        "\n",
        "# # Create datasets from the formatted dictionaries\n",
        "# Trdataset = Dataset.from_dict(train_data)\n",
        "# Vedataset = Dataset.from_dict(valid_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Combine into a DatasetDict\n",
        "# data_dict = DatasetDict({\n",
        "#     'train': Trdataset,\n",
        "#     'valid': Vedataset\n",
        "# })\n",
        "\n"
      ],
      "metadata": {
        "id": "PeZcmz5H0G5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_dict.save_to_disk(r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex4\\Processed_Dataset\")"
      ],
      "metadata": {
        "id": "J_1PRh7v_uZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHESiqsQ6yVB",
        "outputId": "f1fa37b4-6721-48ee-e467-8c9d1f9282e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'text'],\n",
              "        num_rows: 839\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['image', 'text'],\n",
              "        num_rows: 239\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_sample_train = random.randint(0, len(dataset['train']) - 1)\n",
        "print(f\"Random sample from 'train' is {random_sample_train}\")\n",
        "print(f\"Ground Truth is {dataset['train'][random_sample_train]['text']}\")\n",
        "dataset['train'][random_sample_train]['image'].resize((250, 400))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "pPTmEJRSFGBg",
        "outputId": "20229eb7-3064-49f1-cd47-4badc670cc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sample from 'train' is 657\n",
            "Ground Truth is {'latex_1': '\\\\tilde { \\\\Psi } = \\\\lparen \\\\cosh V \\\\rparen \\\\Psi ,', 'latex_2': '\\\\vert \\\\psi \\\\vert ^ { 2 } = \\\\rho =', 'latex_3': '\\\\partial _ { k } T ^ { i k } = O _ { 3 , 3 }', 'latex_4': '\\\\tau _ { s } \\\\approx 1 0 . 1 5', 'latex_5': 'v \\\\mapsto v \\\\otimes L', 'latex_6': 'd ^ { D } r = r ^ { D - 1 } d \\\\Omega _ { D } d r .', 'latex_7': '\\\\hat { t } = - \\\\frac { 1 } { \\\\kappa } \\\\hat { r } .', 'latex_8': 'k _ { 1 } = - q , k _ { 2 } = 3 q - p .'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=250x400>"
            ],
            "image/png": "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",
            "image/jpeg": "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"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def json2token(data):\n",
        "    # Initialize an empty string to build the formatted output\n",
        "    formatted_output = ''\n",
        "\n",
        "    # Loop through each key-value pair in the dictionary\n",
        "    for key, value in data.items():\n",
        "        # Remove commas and format each pair without single quotes\n",
        "        #value = str(value).replace(',', '')  # Remove commas\n",
        "        value = str(value).replace('.', '')\n",
        "        formatted_output += f\"<s_{key}>{value}</s_{key}>\"\n",
        "\n",
        "    # Return the final formatted output string\n",
        "    return formatted_output.strip()  # Remove trailing whitespace\n",
        "\n",
        "\n",
        "# # Example dictionary input\n",
        "# A = {\n",
        "#     'latex1': '\\\\lbrace \\\\dot { X } ^ { \\\\mu } , X _ { \\\\mu } \\\\rbrace = 0 .',\n",
        "#     'latex2': 'J ^ { \\\\mu \\\\nu } = L ^ { \\\\mu \\\\nu } + S ^ { \\\\mu \\\\nu } ,',\n",
        "#     'latex3': 'e ^ { - C } = H _ { 1 } , e ^ { - \\\\chi } = H _ { 2 } .',\n",
        "#     'latex4': 'N _ { \\\\mu \\\\nu } \\\\equiv G _ { \\\\mu \\\\nu } - B _ { \\\\mu \\\\nu } ,',\n",
        "#     'latex5': 'I ^ { \\\\omega } = \\\\bigcup I ^ { \\\\omega } \\\\lparen O \\\\rparen .',\n",
        "#     'latex6': '\\\\partial _ { \\\\mu } h _ { \\\\nu } + \\\\partial _ { \\\\nu }',\n",
        "#     'latex7': '\\\\mu _ { p } = N \\\\sqrt { 1 6 \\\\pi G _ { D } } \\\\tau _ { p } .',\n",
        "#     'latex8': '\\\\nu = l \\\\sinh \\\\rho , \\\\sigma = l \\\\cosh \\\\rho .'\n",
        "# }\n",
        "\n",
        "# # Convert the dictionary to the desired format\n",
        "# output = json2token(A)\n",
        "# print(output)\n"
      ],
      "metadata": {
        "id": "yeAEUue9GXtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "special_tokens = ['<s_latex0>', '</s_latex0>', '<s_latex1>', '</s_latex1>', '<s_latex2>', '</s_latex2>', '<s_latex3>', '</s_latex3>', '<s_latex4>', '</s_latex4>', '<s_latex5>', '</s_latex5>', '<s_latex6>', '</s_latex6>', '<s_latex7>', '</s_latex7>', '<s_latex8>', '</s_latex8>', '<s_latex9>', '</s_latex9>' ]"
      ],
      "metadata": {
        "id": "MnoYU3FMLENr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "task_start_token = '<s>'\n",
        "eos_token = '</s>'\n",
        "\n",
        "def process_documents(sample):\n",
        "\n",
        "  GT_string_single_quote = sample[\"text\"]\n",
        "  GT_string_single_quote = str(GT_string_single_quote)\n",
        "  #print(type(sample[\"text\"]))\n",
        "\n",
        "  GT_string_double_quote = GT_string_single_quote.replace(\"'\", '\"')\n",
        "  text = json.loads(GT_string_double_quote)\n",
        "  d_doc = task_start_token + json2token(text) + eos_token\n",
        "  print('d_doc', d_doc)\n",
        "  image = sample[\"image\"].convert('RGB')\n",
        "  return {\"image\": image, \"text\": d_doc}"
      ],
      "metadata": {
        "id": "oaIM1FL-HzwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = dataset['valid']\n",
        "proc_valid_dataset = valid_dataset.map(process_documents)"
      ],
      "metadata": {
        "id": "uR1HIY-iIwyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train']\n",
        "proc_train_dataset = train_dataset.map(process_documents)"
      ],
      "metadata": {
        "id": "hCyONw5FIyhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(proc_train_dataset), len(proc_valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96awWvygJO2g",
        "outputId": "9f1decc8-db10-4370-f48e-d40c1f5a1853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(839, 239)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proc_train_dataset['text'][322]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSjnu763Jv62",
        "outputId": "e8dcdfd2-1014-4e02-f757-a786c276ae34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s><s_latex_1> c _ { l } \\\\vert _ { y = 0 } = 0 ,</s_latex_1><s_latex_2>\\\\lbrack R \\\\rbrack ^ { \\\\sharp } = 0 </s_latex_2><s_latex_3>Q = \\\\dot { x } _ { i } \\\\psi _ { i } </s_latex_3><s_latex_4>l _ { q } d K = q ^ { - 2 } d K l _ { q } </s_latex_4><s_latex_5>A =</s_latex_5><s_latex_6>V = V _ { + } \\\\oplus V _ { - } ,</s_latex_6><s_latex_7>B = - \\\\frac { \\\\alpha } { 2 n \\\\nu } </s_latex_7><s_latex_8>\\\\lim_{x \\\\to 1} \\\\frac{x^3 - 1}{x - 1} </s_latex_8></s>'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proc_valid_dataset['text'][64]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHMSZpbqJzFH",
        "outputId": "a2509f32-231e-4aec-a61f-8122e13afe52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s><s_latex_1>\\\\gamma = - 1 , \\\\beta = \\\\frac { 2 \\\\pi } { k } ,</s_latex_1><s_latex_2>c _ { 0 } ^ { 2 } + \\\\vec { c } ^ { 2 } = 1</s_latex_2><s_latex_3>W _ { \\\\mu } S = 0 ,</s_latex_3><s_latex_4>\\\\tilde { A } _ { \\\\mu } = A _ { \\\\mu } </s_latex_4><s_latex_5>A U - i B V = U E ,</s_latex_5><s_latex_6>\\\\equiv h _ { i } \\\\delta _ { i j }</s_latex_6><s_latex_7>\\\\tilde { v } \\\\ll \\\\epsilon \\\\lt \\\\frac { 1 } { a } ,</s_latex_7><s_latex_8>V _ { I } q ^ { I } = \\\\frac { 1 } { 3 g } </s_latex_8></s>'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# processor and model token setup"
      ],
      "metadata": {
        "id": "NZRRICJBLlvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderConfig\n",
        "\n",
        "image_size = [720, 960]\n",
        "max_length = 512\n",
        "\n",
        "# update image_size of the encoder\n",
        "# during pre-training, a larger image size was used\n",
        "config = model.config\n",
        "#config = VisionEncoderDecoderConfig.from_pretrained(r\"E:\\Abdul_Muqtadir\\NRPU_HMP_Project\\Weights\\DONUT\\Processor1\")\n",
        "config.encoder.image_size = image_size # (height, width)\n",
        "# update max_length of the decoder (for generation)\n",
        "config.decoder.max_length = max_length"
      ],
      "metadata": {
        "id": "zKIRj9H8LpZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor.tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens + [task_start_token] + [eos_token]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faMBHH8RO7mS",
        "outputId": "d224a5bf-637e-4947-ff5b-102eeadba403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.decoder.resize_token_embeddings(len(processor.tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlIBNZ2WOZA9",
        "outputId": "10689255-c89e-4391-9caf-a3b92a5318e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MBartScaledWordEmbedding(57545, 1024, padding_idx=1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print standard special tokens\n",
        "print(\"Special Tokens:\")\n",
        "print(\"Start token:\", processor.tokenizer.cls_token)\n",
        "print(\"End token:\", processor.tokenizer.sep_token)\n",
        "print(\"Padding token:\", processor.tokenizer.pad_token)\n",
        "print(\"Unknown token:\", processor.tokenizer.unk_token)\n",
        "print(\"Mask token:\", processor.tokenizer.mask_token)\n",
        "\n",
        "# Print any additional tokens that have been added, like custom tags\n",
        "print(\"\\nAdditional Special Tokens:\")\n",
        "for token, idx in processor.tokenizer.get_vocab().items():\n",
        "    if token.startswith(\"<s\") or token.startswith(\"</s\"):\n",
        "        print(f\"{token}: {idx}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haF4qASxOvom",
        "outputId": "c89e8d9b-5dfa-4acb-8758-d042d1ec6060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special Tokens:\n",
            "Start token: <s>\n",
            "End token: </s>\n",
            "Padding token: <pad>\n",
            "Unknown token: <unk>\n",
            "Mask token: <mask>\n",
            "\n",
            "Additional Special Tokens:\n",
            "<sep/>: 57522\n",
            "<s_latex0>: 57525\n",
            "<s_latex5>: 57535\n",
            "</s>: 2\n",
            "</s_latex0>: 57526\n",
            "</s_latex2>: 57530\n",
            "<s_latex1>: 57527\n",
            "<s_latex7>: 57539\n",
            "<s_synthdog>: 57524\n",
            "<s_iitcdip>: 57523\n",
            "</s_latex4>: 57534\n",
            "</s_latex1>: 57528\n",
            "<s_latex4>: 57533\n",
            "<s_latex3>: 57531\n",
            "</s_latex6>: 57538\n",
            "</s_latex3>: 57532\n",
            "</s_latex8>: 57542\n",
            "<s_latex6>: 57537\n",
            "</s_latex5>: 57536\n",
            "</s_latex9>: 57544\n",
            "<s_latex8>: 57541\n",
            "</s_latex7>: 57540\n",
            "<s>: 0\n",
            "<s_latex9>: 57543\n",
            "<s_latex2>: 57529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(['<s>'])[0]"
      ],
      "metadata": {
        "id": "aUVNsoxYwAVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set tokens in the model's configuration\n",
        "model.config.bos_token_id = processor.tokenizer.cls_token_id  # Start token\n",
        "model.config.eos_token_id = processor.tokenizer.sep_token_id  # End token\n",
        "model.config.pad_token_id = processor.tokenizer.pad_token_id  # Padding token\n",
        "\n",
        "print(\"Start token ID:\", model.config.bos_token_id)\n",
        "print(\"End token ID:\", model.config.eos_token_id)\n",
        "print(\"Padding token ID:\", model.config.pad_token_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0YWxMrBPIKJ",
        "outputId": "041164be-62f3-42f1-91e1-5a951fd75acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start token ID: 0\n",
            "End token ID: 2\n",
            "Padding token ID: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the added special tokens\n",
        "added_special_tokens_for_processor_1 = processor.tokenizer.get_added_vocab()\n",
        "print(\"Added special tokens and their IDs:\", added_special_tokens_for_processor_1)\n",
        "print(\"Number of added special tokens:\", len(added_special_tokens_for_processor_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MinM-JpkSiLR",
        "outputId": "36c310ab-b903-48ef-b1f5-c72224d87e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added special tokens and their IDs: {'<s>': 0, '<pad>': 1, '</s>': 2, '<unk>': 3, '<mask>': 57521, '<sep/>': 57522, '<s_iitcdip>': 57523, '<s_synthdog>': 57524, '<s_latex0>': 57525, '</s_latex0>': 57526, '<s_latex1>': 57527, '</s_latex1>': 57528, '<s_latex2>': 57529, '</s_latex2>': 57530, '<s_latex3>': 57531, '</s_latex3>': 57532, '<s_latex4>': 57533, '</s_latex4>': 57534, '<s_latex5>': 57535, '</s_latex5>': 57536, '<s_latex6>': 57537, '</s_latex6>': 57538, '<s_latex7>': 57539, '</s_latex7>': 57540, '<s_latex8>': 57541, '</s_latex8>': 57542, '<s_latex9>': 57543, '</s_latex9>': 57544}\n",
            "Number of added special tokens: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_and_tokenize(sample, max_length=512, ignore_id=1):\n",
        "    # Create tensor from image\n",
        "    try:\n",
        "        pixel_values = processor(\n",
        "            sample[\"image\"], return_tensors=\"pt\"\n",
        "        ).pixel_values.squeeze()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # Tokenize the document\n",
        "    input_ids = processor.tokenizer(\n",
        "        sample[\"text\"],\n",
        "        add_special_tokens=True,  # Add special tokens like [CLS] and [SEP]\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",  # Pad to max_length\n",
        "        truncation=True,  # Truncate if longer than max_length\n",
        "        return_tensors=\"pt\",\n",
        "    )[\"input_ids\"].squeeze(0)\n",
        "\n",
        "    # Prepare labels for the model\n",
        "    labels = input_ids.clone()\n",
        "    labels[labels == processor.tokenizer.pad_token_id] = ignore_id  # Ignore padding tokens\n",
        "\n",
        "    return {\n",
        "        \"pixel_values\": pixel_values,\n",
        "        \"labels\": labels,\n",
        "        \"target_sequence\": sample[\"text\"]  # Include the original text if needed\n",
        "    }\n"
      ],
      "metadata": {
        "id": "_DKjVpZ2PaTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_valid_dataset = proc_valid_dataset.map(\n",
        "    transform_and_tokenize,\n",
        "    batched=True,\n",
        "    batch_size=100,\n",
        "    remove_columns=[\"image\", \"text\"]\n",
        ")"
      ],
      "metadata": {
        "id": "IjPbPAIkchhH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "9e0aee3556fc4359b0946c17137d1208",
            "0c4b0e3efbe1410a98ca1dc597daeb5e",
            "a25295bf9a6a4a8b86616f63d121d4f2",
            "8e5bbb0d5c0c428d9a4482493ea4cbe3",
            "b4443680e837470595f8c2d8f73483ce",
            "65e0d876cb864c53a8595dd10caf9c43",
            "6f6d8575d6524a1883b9109933f05ed5",
            "bde16eb4f33049dc96a09eed14187b8d",
            "a05248cbe4714c85967bb79f1f869c82",
            "20254f0f4d53495d989f0e94c7efea2b",
            "c44c291856ab45da9d78fead54ff5ae5"
          ]
        },
        "outputId": "8b532ed7-c634-451a-b219-6bc2ef1793b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/239 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e0aee3556fc4359b0946c17137d1208"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming proc_train_dataset is your loaded dataset and transform_and_tokenize is the function to process each sample\n",
        "proc_train_dataset = proc_train_dataset.map(\n",
        "    transform_and_tokenize,\n",
        "    batched=True,\n",
        "    batch_size=100,\n",
        "    remove_columns=[\"image\", \"text\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "_owLH5vleDAZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "5f8db19bb9a045639e4e406867263ffd",
            "961f989979ad457ab0975e19b390facc",
            "cd54a8d7a5cb458cadb2ad669ae0a641",
            "619ecc98df3348a88e20ae4b57cbfc76",
            "dc8596e903e5453a9ddb187e2f0aab9d",
            "96afd9f46c1c48b9b7ae0329a02e1492",
            "f88be70ab56e4a73b8d1058e950d6a6b",
            "4bc808865161450c8d96412d7c6074d3",
            "5a204008e16b4c9d9ea0a81582c71736",
            "14fab2db3e704fa4825e5c8048a330eb",
            "96bb099683d843e58687f178af95c528"
          ]
        },
        "outputId": "5f546f44-f442-4158-b437-a9d60d726f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/839 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f8db19bb9a045639e4e406867263ffd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_dataset = proc_train_dataset"
      ],
      "metadata": {
        "id": "djOqlvC7j1oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import concatenate_datasets\n",
        "\n",
        "# # Combine the datasets\n",
        "# combined_dataset = concatenate_datasets([small_processed_train_dataset1, small_processed_train_dataset2])\n",
        "\n",
        "# # Display the combined dataset\n",
        "# print(combined_dataset)\n"
      ],
      "metadata": {
        "id": "OkK1Kny-ucGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Limit to the first 10 samples\n",
        "# small_valid_dataset = proc_valid_dataset.select(range(100))\n",
        "\n",
        "# # Apply the transformation only on these 10 samples\n",
        "# small_processed_valid_dataset = small_valid_dataset.map(transform_and_tokenize, remove_columns=[\"image\", \"text\"])\n"
      ],
      "metadata": {
        "id": "Dutbq4gNPxQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# small_processed_valid_dataset"
      ],
      "metadata": {
        "id": "JJcKIF2hVA6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# small_processed_valid_dataset['target_sequence'][0]"
      ],
      "metadata": {
        "id": "QGaqrP6KVDOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_dataset['target_sequence'][0]"
      ],
      "metadata": {
        "id": "eowPr__7j0CG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7a1f04-12f2-4de4-84b4-111e7bd040c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s><s_latex_1>2 r \\\\frac { \\\\partial _ { 0 } \\\\beta } { \\\\beta } = 0</s_latex_1><s_latex_2>j _ { + } = \\\\mu , \\\\bar { \\\\jmath } _ { - } = \\\\nu ,</s_latex_2><s_latex_3>\\\\log_{10}(3xy) </s_latex_3><s_latex_4>w _ { I } = P - \\\\rho ,</s_latex_4><s_latex_5>D _ { \\\\mu } = \\\\partial _ { \\\\mu } + i e A _ { \\\\mu }</s_latex_5><s_latex_6>\\\\lparen A _ { \\\\pm } + \\\\alpha C _ { \\\\pm } \\\\rparen</s_latex_6><s_latex_7>3x + 2y + z = 8 </s_latex_7><s_latex_8>\\\\lparen \\\\bar { S } , \\\\bar { S } \\\\rparen = 0 </s_latex_8></s>'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the labels of the first sample in `small_processed_valid_dataset`\n",
        "decoded_labels = processor.tokenizer.decode(processed_train_dataset['labels'][0], skip_special_tokens=False)\n",
        "print(decoded_labels)\n"
      ],
      "metadata": {
        "id": "jU_3eJkaVL81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564835a6-9ef4-4134-bd7d-dfaa2f949dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s><s> <s_latex_<unk>>2 r \\frac { \\partial _ { 0 } \\beta } { \\beta } = 0</s_latex_<unk>><s_latex_2>j _ { + } = \\mu , \\bar { \\jmath } _ { - } = \\nu ,</s_latex_2><s_latex_3>\\log_{10}(3xy) </s_latex_3><s_latex_4>w _ { I } = P - \\rho ,</s_latex_4><s_latex_5>D _ { \\mu } = \\partial _ { \\mu } + i e A _ { \\mu }</s_latex_5><s_latex_6>\\lparen A _ { \\pm } + \\alpha C _ { \\pm } \\rparen</s_latex_6><s_latex_7>3x + 2y + z = 8 </s_latex_7><s_latex_8>\\lparen \\bar { S } , \\bar { S } \\rparen = 0 </s_latex_8></s></s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VkU8dnCwumV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import wandb\n",
        "# wandb.login(key='64b4c0e264e78227e0ef7ffd55e5236e5665e193')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZvLS1qjVWO9",
        "outputId": "8259233c-2aad-44fc-fab4-08005c42ef25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstudydrive-ee\u001b[0m (\u001b[33mabdul1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\DataInsight GPU\\.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Unable to read C:\\Users\\DataInsight GPU\\.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.finish()\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "#wandb.init(project=\"Thesis\", name=\"light_donut_MathOCR_Iam2Latex4\")\n",
        "wandb.init(project=\"Thesis\", name=\"DONUT_to_Iamlatex2_B\")\n",
        "wandb_logger = WandbLogger()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "d5HKFcVwuvMb",
        "outputId": "83df1393-279c-4d1b-c667-0f69d941be7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstudydrive-ee\u001b[0m (\u001b[33mabdul1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.18.7 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\DataInsight GPU\\wandb\\run-20241120_114138-zsf589mb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abdul1/Thesis/runs/zsf589mb' target=\"_blank\">DONUT_to_Iamlatex2_B</a></strong> to <a href='https://wandb.ai/abdul1/Thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abdul1/Thesis' target=\"_blank\">https://wandb.ai/abdul1/Thesis</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abdul1/Thesis/runs/zsf589mb' target=\"_blank\">https://wandb.ai/abdul1/Thesis/runs/zsf589mb</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfFolder\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "# hyperparameters used for multiple args\n",
        "OUTPUT_DIRECTORY = r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\model_save_dirctory2\"\n",
        "\n",
        "# Arguments for training\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=OUTPUT_DIRECTORY,\n",
        "    num_train_epochs=15,  # for EUGD = 2\n",
        "    learning_rate=0.0001,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=15,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=200,  # Evaluate every 500 steps\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,  # Save checkpoint every 500 steps\n",
        "    # predict_with_generate=True,\n",
        "    # push to hub parameters\n",
        "    report_to=\"wandb\",\n",
        "    # push_to_hub=True,\n",
        "    # hub_strategy=\"every_save\",\n",
        "    # hub_model_id=hf_repository_id,\n",
        "    # hub_token=HfFolder.get_token(),\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHsgvAUpu3Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab4ba07-7b16-4161-f147-3b0b2ac4e6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_train_dataset,\n",
        "    eval_dataset=processed_valid_dataset\n",
        ")\n"
      ],
      "metadata": {
        "id": "h26DAsMGvXUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n-Mr7J9LWnlT",
        "outputId": "e01ab2e0-41d3-4a59-b38d-585140c7745b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "C:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:495: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1118' max='12585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1118/12585 9:59:19 < 102:38:11, 0.03 it/s, Epoch 1.33/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.037549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.038100</td>\n",
              "      <td>0.031007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>0.026878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.017205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.018736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002313F6A40D0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\DataInsight GPU\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 785, in _clean_thread_parent_frames\n",
            "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Anaconda3\\envs\\newdonut\\Lib\\threading.py\", line 1501, in enumerate\n",
            "    def enumerate():\n",
            "    \n",
            "KeyboardInterrupt: \n",
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002313F6A40D0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\DataInsight GPU\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 785, in _clean_thread_parent_frames\n",
            "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Anaconda3\\envs\\newdonut\\Lib\\threading.py\", line 1501, in enumerate\n",
            "    def enumerate():\n",
            "    \n",
            "KeyboardInterrupt: \n",
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002313F6A40D0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\DataInsight GPU\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 785, in _clean_thread_parent_frames\n",
            "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Anaconda3\\envs\\newdonut\\Lib\\threading.py\", line 1501, in enumerate\n",
            "    def enumerate():\n",
            "    \n",
            "KeyboardInterrupt: \n",
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002313F6A40D0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\DataInsight GPU\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 785, in _clean_thread_parent_frames\n",
            "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Anaconda3\\envs\\newdonut\\Lib\\threading.py\", line 1501, in enumerate\n",
            "    def enumerate():\n",
            "    \n",
            "KeyboardInterrupt: \n",
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002313F6A40D0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\DataInsight GPU\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "\n",
            "KeyboardInterrupt: \n",
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002313F6A40D0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\DataInsight GPU\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 785, in _clean_thread_parent_frames\n",
            "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Anaconda3\\envs\\newdonut\\Lib\\threading.py\", line 1501, in enumerate\n",
            "    def enumerate():\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zIUL7S3JRvj2",
        "outputId": "d09cb722-8bfc-4dc6-f27a-f82da49257e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "C:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:495: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2212' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2212/9000 16:16:00 < 49:57:48, 0.04 it/s, Epoch 3.69/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.192000</td>\n",
              "      <td>0.175785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.190900</td>\n",
              "      <td>0.173918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.180500</td>\n",
              "      <td>0.169213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.167945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.167500</td>\n",
              "      <td>0.159763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.165100</td>\n",
              "      <td>0.152323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.153300</td>\n",
              "      <td>0.149445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.152000</td>\n",
              "      <td>0.152998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.149400</td>\n",
              "      <td>0.146569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.141100</td>\n",
              "      <td>0.142288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.141900</td>\n",
              "      <td>0.144568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\trainer.py:2426\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2424\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2425\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[1;32m-> 2426\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs \u001b[38;5;129;01min\u001b[39;00m batch_samples:\n\u001b[0;32m   2428\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\trainer.py:5038\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[1;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[0;32m   5036\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[0;32m   5037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5038\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(epoch_iterator)]\n\u001b[0;32m   5039\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   5040\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\accelerate\\data_loader.py:462\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 462\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:60\u001b[0m, in \u001b[0;36mpin_memory\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)({k: pin_memory(sample, device) \u001b[38;5;28;01mfor\u001b[39;00m k, sample \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()})  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
            "File \u001b[1;32m<frozen abc>:117\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzeDq-JYRvgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKHNbo9rRveQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oPjNL5zmRvbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kgv_1omORvYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "fzMYVwSWs1uN",
        "outputId": "ebf721c3-9ffd-481c-b844-c038f94b909f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "C:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:495: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4334' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4334/9000 35:59:05 < 38:45:33, 0.03 it/s, Epoch 7.22/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.729200</td>\n",
              "      <td>1.016740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.905900</td>\n",
              "      <td>0.831146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.791800</td>\n",
              "      <td>0.738279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.718100</td>\n",
              "      <td>0.682350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.671500</td>\n",
              "      <td>0.640404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.642200</td>\n",
              "      <td>0.605491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.601500</td>\n",
              "      <td>0.572437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.559200</td>\n",
              "      <td>0.539205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.528200</td>\n",
              "      <td>0.499801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.488600</td>\n",
              "      <td>0.447072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.447900</td>\n",
              "      <td>0.407684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.408800</td>\n",
              "      <td>0.368698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.356400</td>\n",
              "      <td>0.335529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.324000</td>\n",
              "      <td>0.300877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.293700</td>\n",
              "      <td>0.261109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.262300</td>\n",
              "      <td>0.241175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.239300</td>\n",
              "      <td>0.210501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.220300</td>\n",
              "      <td>0.199003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.199100</td>\n",
              "      <td>0.184275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.191300</td>\n",
              "      <td>0.176935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.180800</td>\n",
              "      <td>0.161539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3OEjgdkZs1p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3E7J6T1Hs1mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUTT8k24s1kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7-YNaUIs1hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7BsX5rss1fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pM9pmwpbs1dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "OVOb-TgJvaZb",
        "outputId": "66342b22-a3b4-4743-8b31-aaec9c990ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "C:\\Anaconda3\\envs\\newdonut\\Lib\\site-packages\\transformers\\models\\mbart\\modeling_mbart.py:495: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='309' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 309/6000 1:58:08 < 36:30:05, 0.04 it/s, Epoch 0.51/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.663600</td>\n",
              "      <td>0.600168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference and Evaluation"
      ],
      "metadata": {
        "id": "ndT0ht0Tbo6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionEncoderDecoderModel.from_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\checkpoint-800\")\n",
        "#processor = DonutProcessor.from_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\FW\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zvyHXX3RfoqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc0cc56-c31d-4bb1-fdfc-4958a661db22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.donut.modeling_donut_swin.DonutSwinModel'> is overwritten by shared encoder config: DonutSwinConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"depths\": [\n",
            "    2,\n",
            "    2,\n",
            "    14,\n",
            "    2\n",
            "  ],\n",
            "  \"drop_path_rate\": 0.1,\n",
            "  \"embed_dim\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"image_size\": [\n",
            "    720,\n",
            "    960\n",
            "  ],\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"mlp_ratio\": 4.0,\n",
            "  \"model_type\": \"donut-swin\",\n",
            "  \"num_channels\": 3,\n",
            "  \"num_heads\": [\n",
            "    4,\n",
            "    8,\n",
            "    16,\n",
            "    32\n",
            "  ],\n",
            "  \"num_layers\": 4,\n",
            "  \"patch_size\": 4,\n",
            "  \"path_norm\": true,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_absolute_embeddings\": false,\n",
            "  \"window_size\": 10\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.mbart.modeling_mbart.MBartForCausalLM'> is overwritten by shared decoder config: MBartConfig {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 4,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 1536,\n",
            "  \"model_type\": \"mbart\",\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": true,\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 57545\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionEncoderDecoderModel(\n",
              "  (encoder): DonutSwinModel(\n",
              "    (embeddings): DonutSwinEmbeddings(\n",
              "      (patch_embeddings): DonutSwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): DonutSwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-13): 14 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (decoder): MBartForCausalLM(\n",
              "    (model): MBartDecoderWrapper(\n",
              "      (decoder): MBartDecoder(\n",
              "        (embed_tokens): MBartScaledWordEmbedding(57545, 1024, padding_idx=1)\n",
              "        (embed_positions): MBartLearnedPositionalEmbedding(1538, 1024)\n",
              "        (layers): ModuleList(\n",
              "          (0-3): 4 x MBartDecoderLayer(\n",
              "            (self_attn): MBartSdpaAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (activation_fn): GELUActivation()\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (encoder_attn): MBartSdpaAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (lm_head): Linear(in_features=1024, out_features=57545, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8IdIyCsegBq",
        "outputId": "da56c051-652c-4ed6-dc07-e33fdfbf5754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201868408"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "Y9hpnMC6fwmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imag_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex\\testing\\generated_template_1.jpg\""
      ],
      "metadata": {
        "id": "Ev7SBVbpvkGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "imag_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex\\testing\\generated_template_1.jpg\"\n",
        "img = Image.open(imag_path)"
      ],
      "metadata": {
        "id": "ykMW6n7rP-1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "c3dafbab-47a3-4899-9722-4b537dfae116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'E:\\\\Abdul_Muqtadir\\\\Thesis\\\\Dataset\\\\Test_Iamlatex\\\\testing\\\\generated_template_1.jpg'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      2\u001b[0m imag_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAbdul_Muqtadir\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mThesis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTest_Iamlatex\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgenerated_template_1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimag_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\Abdul_Muqtadir\\\\Thesis\\\\Dataset\\\\Test_Iamlatex\\\\testing\\\\generated_template_1.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(img):\n",
        "  inputs = processor(images=img, return_tensors=\"pt\")\n",
        "  generated_ids = model.generate(pixel_values=inputs[\"pixel_values\"].to(device), max_length = 512)\n",
        "  generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "  return generated_text"
      ],
      "metadata": {
        "id": "wnmd29KLQDg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_latex_equations(input_str):\n",
        "\n",
        "    #input_str\n",
        "    # Regular expression to match both numbered and unknown latex tags\n",
        "    matches = re.findall(r'<s_latex(?:_(\\d+|<unk>))>(.*?)</s_latex(?:_\\1)>', input_str)\n",
        "\n",
        "    # Create the dictionary with formatted keys and LaTeX content\n",
        "    latex_dict = {}\n",
        "    for num, content in matches:\n",
        "        if num == \"<unk>\":\n",
        "            latex_dict[\"latex_1\"] = content.strip() # Map unknown tag to latex_1\n",
        "        else:\n",
        "            latex_dict[f\"latex_{num}\"] = content.strip()\n",
        "\n",
        "    return latex_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "yb1biZQ_QPue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hq7P482NIh_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "# Define the directory containing images and JSON output directory\n",
        "image_dir = r'E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\Final_Test_Dataset'\n",
        "json_output_dir = r'E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\Final_Test_Dataset\\donut_output'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(json_output_dir, exist_ok=True)\n",
        "\n",
        "# Loop through each file in the image directory\n",
        "for filename in os.listdir(image_dir):\n",
        "    # Check if the file is an image (e.g., .jpg or .png)\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Convert to lowercase for consistent matching\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        # Open the image using PIL\n",
        "        img = Image.open(image_path)\n",
        "\n",
        "        # Perform inference and extract LaTeX equations\n",
        "        inference_text = inference(img)\n",
        "        print(inference_text)\n",
        "        generated_text = extract_latex_equations(inference_text)\n",
        "\n",
        "        # Prepare the data to be saved in JSON format\n",
        "        data = generated_text\n",
        "        #print(generated_text)\n",
        "\n",
        "        # Define the output JSON file path with the same name as the image but with a .json extension\n",
        "        json_filename = os.path.splitext(filename)[0] + '.json'\n",
        "        json_path = os.path.join(json_output_dir, json_filename)\n",
        "\n",
        "        # Save the generated LaTeX equation to the JSON file\n",
        "        with open(json_path, 'w') as json_file:\n",
        "            json.dump(data, json_file, indent=4)\n",
        "\n",
        "        print(f\"Generated LaTeX for {filename} saved to {json_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdg4BpbMVPBx",
        "outputId": "364988f7-ffb9-4e2c-9bbd-dab71568b1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s><s><s> <s_latex_<unk>>x + 2y - \\sqrt{z} = 9 </s_latex_<unk>><s_latex_2>\\lim_{x \\to \\infty} \\frac{5x^4 + x^2}{e^x} </s_latex_2><s_latex_3>e^{x^2} </s_latex_3><s_latex_4>x^2 + \\frac{<unk>}{y}{y} = 5 </s_latex_4><s_latex_5>2x + \\sqrt{y} + z^3 = 6 </s_latex_5><s_latex_6>\\lim_{x \\to 2} \\frac{x^2} - 10 9 6}{x - 2} </s_latex_6><s_latex_7>x^3 + y = 0 </s_latex_7><s_latex_8>\\lim_{x \\to \\infty} \\frac{x^5}{x^5 + 7x^2} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_1.jpg saved to generated_template_1.json\n",
            "<s><s><s> <s_latex_<unk>>3x + 2y + z = 6 </s_latex_<unk>><s_latex_2>\\ln(5x + y) </s_latex_2><s_latex_3>\\frac{2 + 2}{y} + 1 = 0 </s_latex_3><s_latex_4>x + y^2 + z^3 = 10 </s_latex_4><s_latex_5>\\lim_{x \\to 2} \\frac{x^2 - 109 6} </s_latex_5><s_latex_6>\\lim_{x \\to 1} \\frac{x^2 - 1}{x - 1} </s_latex_6><s_latex_7>x^2 + \\frac{<unk>}{y} = z^2 </s_latex_7><s_latex_8>\\lim_{x \\to 1} \\frac{x^2 - 1}{x - 1} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_10.jpg saved to generated_template_10.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to \\infty} \\frac{x^6}{e^x + x^2} </s_latex_<unk>><s_latex_2>\\chi \\ast _ { s } \\chi ^ { - 1 } = 1 ,</s_latex_2><s_latex_3>\\nabla ^ { A } h _ { A B } = 0 , h = 0 </s_latex_3><s_latex_4>D \\chi = \\Pi _ { n } d c ^ { n } </s_latex_4><s_latex_5>\\langle V , V \\rangle = 0 \\Rightarrow V = 0 </s_latex_5><s_latex_6>d _ { 2 } = 2 p , d _ { 3 } = 3 q + 1 </s_latex_6><s_latex_7>F = d x ^ { - } \\wedge \\varphi ,</s_latex_7><s_latex_8>\\Gamma _ { D } = \\Gamma _ { W } \\times M o n</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_1079.jpg saved to generated_template_1079.json\n",
            "<s><s><s> <s_latex_<unk>>\\lparen i \\partial / - m \\rparen \\psi = 0 </s_latex_<unk>><s_latex_2>R ^ { 1 0 } = R ^ { p + 1 } \\times R ^ { 9 - p } ,</s_latex_2><s_latex_3>c ^ { \\# } = 2 6 , a ^ { \\# } = 1 ,</s_latex_3><s_latex_4>\\lt T _ { \\mu \\nu } \\gt _ { f i n } ^ { i n } =</s_latex_4><s_latex_5>O = \\gamma _ { + + } = \\gamma _ { - }</s_latex_5><s_latex_6>\\frac { \\partial W } { \\partial \\phi _ { i } } = 0</s_latex_6><s_latex_7>x^3 + \\sqrt{y} + z = 9 </s_latex_7><s_latex_8>\\lambda = 8 + 2 t , t \\in N _ { 0 } ,</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_1093.jpg saved to generated_template_1093.json\n",
            "<s><s><s> <s_latex_<unk>>2x + y^2 + z^3 = 7 </s_latex_<unk>><s_latex_2>3x^2 + y + 2x = 0 </s_latex_2><s_latex_3>x + y + \\sqrt{z} = 4 </s_latex_3><s_latex_4>\\lim_{x \\to \\infty} \\frac{5x^4 + x^2}{e^x} </s_latex_4><s_latex_5>3x + 2y + z = 6 </s_latex_5><s_latex_6>\\ln(yy + 2) </s_latex_6><s_latex_7>\\frac{x + y}{z} + 1 = 0 </s_latex_7><s_latex_8>\\lim_{x \\to 0} \\frac{\\sin(9x)}{x} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_11.jpg saved to generated_template_11.json\n",
            "<s><s><s> <s_latex_<unk>>x + y + z + \\sqrt{xy} = 5 </s_latex_<unk>><s_latex_2>\\sigma _ { l } \\lparen T \\rparen = T ^ { l }</s_latex_2><s_latex_3>A ^ { \\prime } = W \\lparen \\Phi \\rparen </s_latex_3><s_latex_4>\\ln(2 + 5)x) </s_latex_4><s_latex_5>\\lambda _ { - } = \\sigma \\circ \\lambda _ { + } </s_latex_5><s_latex_6>F _ { i j } = \\epsilon _ { i j k } D _ { k } \\phi</s_latex_6><s_latex_7>X \\cdot X = 0 , X \\cdot P = 0 , P \\cdot P = 0 ,</s_latex_7><s_latex_8>\\eta = \\sqrt { \\frac { L } { N } } </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_1118.jpg saved to generated_template_1118.json\n",
            "<s><s><s> <s_latex_<unk>>I _ { 1 } = L _ { 1 } , I _ { 2 } = L _ { 2 }</s_latex_<unk>><s_latex_2>3 W _ { 4 } + 2 W _ { 5 } </s_latex_2><s_latex_3>A = i Q \\frac { B } { 4 } \\sin \\chi \\psi d \\chi </s_latex_3><s_latex_4>\\tau \\rightarrow \\tau + 1</s_latex_4><s_latex_5>\\partial _ { k } T ^ { i k } = O _ { 3 , 3 }</s_latex_5><s_latex_6>= \\lparen n + \\frac { p } { 2 } \\rparen</s_latex_6><s_latex_7>\\vartheta \\rightarrow \\vartheta - \\alpha</s_latex_7><s_latex_8>\\alpha = \\sqrt { \\frac { 1 + v } { 2 - v } } </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_116.jpg saved to generated_template_116.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to \\infty} \\frac{5x^4 + x^2}{e^x} </s_latex_<unk>><s_latex_2>\\lim_{x \\to \\infty} \\frac{5x^2 + 1} </s_latex_2><s_latex_3>x^2 + y = 2 </s_latex_3><s_latex_4>\\lim_{x \\to \\infty} \\frac{x}{x^2} </s_latex_4><s_latex_5>\\ln(x^2 + y^2 \\rparen</s_latex_5><s_latex_6>\\lim_{x \\to \\infty} \\frac{x^3}{e^x} </s_latex_6><s_latex_7>5x + 2y - z = 6 </s_latex_7><s_latex_8>x^2 - 2x + \\frac{12}}{x} = 5 </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_12.jpg saved to generated_template_12.json\n",
            "<s><s><s> <s_latex_<unk>>S = - \\frac { T } { 2 }</s_latex_<unk>><s_latex_2>F _ { L } ^ { 3 } = - \\frac { 1 } { q } \\omega ,</s_latex_2><s_latex_3>\\Phi = 2 \\sqrt { 3 } U</s_latex_3><s_latex_4>- C ^ { T } = C = \\beta C \\beta C ^ { 2 } = - 1</s_latex_4><s_latex_5>\\rho _ { 1 } \\omega = \\omega , \\rho _ { 2 } \\Psi = 0 </s_latex_5><s_latex_6>\\chi = \\chi \\star \\chi</s_latex_6><s_latex_7>D _ { 1 } a = \\frac { 1 } { 2 } D _ { 2 } z ,</s_latex_7><s_latex_8>D : S \\rightarrow S + \\lambda ,</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_129.jpg saved to generated_template_129.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to 0} \\frac{\\tan(14x)} </s_latex_<unk>><s_latex_2>\\sqrt{x}x + y + z = 5 </s_latex_2><s_latex_3>2e^{-2x + 3} </s_latex_3><s_latex_4>3x + 2y + z = 6 </s_latex_4><s_latex_5>\\psi _ { 3 } + z = 2x </s_latex_5><s_latex_6>\\lim_{x \\to \\infty} \\frac{e^x}{x} </s_latex_6><s_latex_7>10e^{x/s} </s_latex_7><s_latex_8>\\frac{2}{y} - z = 2 </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_13.jpg saved to generated_template_13.json\n",
            "<s><s><s> <s_latex_<unk>>\\log_{10}(y + 1) </s_latex_<unk>><s_latex_2>\\lim_{x \\to \\infty} \\frac{5x^2 + x}{x^2 + 1} </s_latex_2><s_latex_3>\\lim_{x \\to \\infty} \\frac{8x^7 + x^6}{e^x} </s_latex_3><s_latex_4>x^3 + y = 0 </s_latex_4><s_latex_5>x^2 + y + 2x^2 = 5 </s_latex_5><s_latex_6>3x + y + z^2 = 5 </s_latex_6><s_latex_7>\\lim_{x \\to 0} \\frac{2x} - 1}{x} </s_latex_7><s_latex_8>\\lim_{x \\to \\frac{x^3 - 1}{x} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_14.jpg saved to generated_template_14.json\n",
            "<s><s><s> <s_latex_<unk>>x + 2y - \\sqrt{z} = 9 </s_latex_<unk>><s_latex_2>2x + \\sqrt{y} + z^3 = 6 </s_latex_2><s_latex_3>3e^{2x - y} </s_latex_3><s_latex_4>8e^{-3y} </s_latex_4><s_latex_5>\\ln(2y) </s_latex_5><s_latex_6>x^2 + \\frac{<unk>}{y} = z^2 </s_latex_6><s_latex_7>\\lim_{x \\to \\infty} \\frac{x^4}{e^x} </s_latex_7><s_latex_8>\\lim_{x \\to \\infty} \\frac{x^4}{x^4 + 1} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_15.jpg saved to generated_template_15.json\n",
            "<s><s><s> <s_latex_<unk>>x + 2y - \\sqrt{z} = g </s_latex_<unk>><s_latex_2>x + y + z^2 = 7 </s_latex_2><s_latex_3>\\ln(x^2 + y^2 </s_latex_3><s_latex_4>\\log_{10}(y + 1) </s_latex_4><s_latex_5>\\sqrt{x + y + z} = 5 </s_latex_5><s_latex_6>\\lim_{x \\to 2} \\frac{x^2 - 4}{x - 2} </s_latex_6><s_latex_7>\\lim_{x \\to \\infty} \\frac{x + x^6}{e^x} </s_latex_7><s_latex_8>2x + y^2 + z^3 = 7 </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_16.jpg saved to generated_template_16.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to \\infty} \\frac{x^6 - 4x^3}{x^6 + 1} </s_latex_<unk>><s_latex_2>\\lim_{x \\to 1} \\frac{x^4 - 1}{x - 1} </s_latex_2><s_latex_3>\\frac{x + y}{z} + 1 = 0 </s_latex_3><s_latex_4>\\lim_{x \\to 1} \\frac{x^4 - 1}{x - 1} </s_latex_4><s_latex_5>x^2 + y^2 - z^3 = 0 </s_latex_5><s_latex_6>x^2 + \\frac{<unk>}{y} = 5 </s_latex_6><s_latex_7>10e^2 + 3 </s_latex_7><s_latex_8>4e^{x + 3} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_17.jpg saved to generated_template_17.json\n",
            "<s><s><s> <s_latex_<unk>>\\hat { \\Phi } = h \\lparen x \\rparen \\tau _ { r } ,</s_latex_<unk>><s_latex_2>x _ { 3 } + r _ { - 1 } , j = 1 , \\ldots , r ,</s_latex_2><s_latex_3>\\omega ^ { a } \\equiv e ^ { a }</s_latex_3><s_latex_4>\\ddot { y } = 0 ; \\ddot { z } = 0</s_latex_4><s_latex_5>\\frac { 1 } { 2 4 } \\chi \\lparen X _ { 4 } \\rparen</s_latex_5><s_latex_6>\\Delta \\phi =</s_latex_6><s_latex_7>x^2 + 3y + z = 6 </s_latex_7><s_latex_8>d A + r F _ { i } = C , i = 1 , n</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_171.jpg saved to generated_template_171.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to 0} \\frac{\\tan(13x} </s_latex_<unk>><s_latex_2>4e^{x + 3} </s_latex_2><s_latex_3>8e^{-3y} </s_latex_3><s_latex_4>\\sqrt{x + y + z} = 5 </s_latex_4><s_latex_5>2x + 3 = y </s_latex_5><s_latex_6>3x + y + z^2 = 5 </s_latex_6><s_latex_7>\\lim_{x \\to 2} \\frac{12} - 4109 6}{x - 2} </s_latex_7><s_latex_8>\\ln(x - 2y) </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_18.jpg saved to generated_template_18.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to \\infty} \\frac{8x^7 + x^6}{e^x} </s_latex_<unk>><s_latex_2>\\log_{4}(2x + 1) </s_latex_2><s_latex_3>8e^{-3y} </s_latex_3><s_latex_4>x + y + \\sqrt{z} = 4 </s_latex_4><s_latex_5>3x + 2y + z = 6 </s_latex_5><s_latex_6>2x + 3 = y </s_latex_6><s_latex_7>x^2 + y = 2 </s_latex_7><s_latex_8>\\lim_{x \\to \\infty} \\frac{x^4x^3}{x^4 + 1} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_19.jpg saved to generated_template_19.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to 1} \\frac{x^7 - 1}{x - 1} </s_latex_<unk>><s_latex_2>e^{-3 \\sqrt{x} </s_latex_2><s_latex_3>3x^2 + y + 2x = 0 </s_latex_3><s_latex_4>3x + 2y + z = 6 </s_latex_4><s_latex_5>x + y + z^2 = 7 </s_latex_5><s_latex_6>\\ln(x - 2y) </s_latex_6><s_latex_7>\\ln(2y) </s_latex_7><s_latex_8>\\lim_{x \\to 0} \\frac{\\sin(9x)}{x} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_2.jpg saved to generated_template_2.json\n",
            "<s><s><s> <s_latex_<unk>>\\log_{4}(5 + z) </s_latex_<unk>><s_latex_2>\\lim_{x \\to 2} \\frac{x^2} - 4}{x - 2} </s_latex_2><s_latex_3>\\lim_{x \\to 0} \\frac{\\sin(14x)}{x} </s_latex_3><s_latex_4>\\lim_{x \\to 0} \\frac{x^4x} </s_latex_4><s_latex_5>\\lim_{x \\to 1} \\frac{x^2 - 4}{x - 2} </s_latex_5><s_latex_6>\\lim_{x \\to 2} \\frac{x^2 - 4}{x - 2} </s_latex_6><s_latex_7>\\lim_{x \\to 2} \\frac{x^2x^3}{x^4 + 1} </s_latex_7><s_latex_8>\\lim_{x \\to \\infty} \\frac{x^4 - 2x^3}{x^4 + 1} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_20.jpg saved to generated_template_20.json\n",
            "<s><s><s> <s_latex_<unk>>T = g ^ { - 1 } P g </s_latex_<unk>><s_latex_2>L \\sim \\sqrt { - \\det G _ { \\alpha \\beta } }</s_latex_2><s_latex_3>\\tilde { \\Psi } = \\lparen \\cosh V \\rparen \\Psi ,</s_latex_3><s_latex_4>2e^{-\\sqrt{z}} </s_latex_4><s_latex_5>\\mu</s_latex_5><s_latex_6>E ^ { 2 } = E , E ^ { \\dagger } = E ,</s_latex_6><s_latex_7>\\Lambda = \\frac { d Y } { d G } G - Y</s_latex_7><s_latex_8>\\chi = \\chi \\star \\chi</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_200.jpg saved to generated_template_200.json\n",
            "<s><s><s> <s_latex_<unk>>\\nabla ^ { 2 } g _ { 0 0 0 } = 8 \\pi G T _ { 0 0 0 } </s_latex_<unk>><s_latex_2>4e^{-\\frac{x}{2} </s_latex_2><s_latex_3>\\Phi = \\Phi _ { 0 } + \\tilde { \\Phi } </s_latex_3><s_latex_4>e^{x^2 + 2y} + 2y </s_latex_4><s_latex_5>\\vert \\psi \\vert ^ { 2 } = \\rho =</s_latex_5><s_latex_6>G = Q ^ { \\dagger } \\bar { G } Q ,</s_latex_6><s_latex_7>F _ { 0 } = \\frac { e n } { Z } , n \\in Z </s_latex_7><s_latex_8>\\lim_{x \\to 0} \\frac{8x - 1}{x} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_233.jpg saved to generated_template_233.json\n",
            "<s><s><s> <s_latex_<unk>>z = \\frac { \\omega \\tau } { 2 }</s_latex_<unk>><s_latex_2>a _ { 0 , 1 , 2 , 3 } \\in R </s_latex_2><s_latex_3>g ^ { \\dagger } H g = H </s_latex_3><s_latex_4>k _ { 1 } \\approx \\pm \\alpha k _ { 2 }</s_latex_4><s_latex_5>g : X ^ { I } \\rightarrow U ^ { I J } X ^ { J } </s_latex_5><s_latex_6>\\lim_{x \\to 0} \\frac{sin x}{x} </s_latex_6><s_latex_7>F = \\frac { Q } { r ^ { 2 } } d t \\wedge d r</s_latex_7><s_latex_8>\\exp i \\pi \\kappa = \\zeta</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_293.jpg saved to generated_template_293.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to 0} \\frac{\\sin(9x)}{x} </s_latex_<unk>><s_latex_2>\\lim_{x \\to 0} \\frac{\\sin(14x)}{x} </s_latex_2><s_latex_3>\\ln(x - 2y) </s_latex_3><s_latex_4>\\frac{x}{y} - z = 2 </s_latex_4><s_latex_5>x^2 + \\sqrt{y} + z = 10 </s_latex_5><s_latex_6>\\log_{10}(x^2 + 1) </s_latex_6><s_latex_7>\\psi _ { 3 } + z = 2x</s_latex_7><s_latex_8>\\lim_{x \\to \\infty} \\frac{x}{x^2} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_3.jpg saved to generated_template_3.json\n",
            "<s><s><s> <s_latex_<unk>>A = \\int d ^ { 2 } \\sigma \\eta ^ { 1 / 2 }</s_latex_<unk>><s_latex_2>\\lim_{x \\to 2} \\frac{x^4 - 6 3 8 4}{x - 2} </s_latex_2><s_latex_3>\\frac{\\partial \\Phi } { \\partial J _ { x } } = 0</s_latex_3><s_latex_4>S _ { m a x } \\simeq S _ { B H } ^ { 3 / 4 } </s_latex_4><s_latex_5>T \\rightarrow \\frac { 1 } { T } </s_latex_5><s_latex_6>\\partial _ { s } A _ { \\mu } = 0 , A _ { s } = 0 </s_latex_6><s_latex_7>Z = J \\int D q e ^ { - S \\lbrack q \\rbrack ,</s_latex_7><s_latex_8>d N \\propto l ^ { 1 - b } d l </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_346.jpg saved to generated_template_346.json\n",
            "<s><s><s> <s_latex_<unk>>D _ { i } \\Sigma _ { \\alpha } ^ { i } = 0</s_latex_<unk>><s_latex_2>\\delta g = g i \\lambda - i \\bar { \\lambda } g</s_latex_2><s_latex_3>E \\ge \\pm \\frac { v ^ { 2 } } { \\kappa } Q </s_latex_3><s_latex_4>S _ { B I } = \\int d t d \\phi L _ { B I }</s_latex_4><s_latex_5>\\nabla _ { \\chi } \\chi = 0 </s_latex_5><s_latex_6>8e^{x + y} </s_latex_6><s_latex_7>\\theta = \\frac { 2 \\pi n y } { L }</s_latex_7><s_latex_8>\\Pi _ { + q } ^ { \\underline { m } } } = 0</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_355.jpg saved to generated_template_355.json\n",
            "<s><s><s> <s_latex_<unk>>e^x / 2 </s_latex_<unk>><s_latex_2>x + y + z^2 = 7 </s_latex_2><s_latex_3>x^2 + \\sqrt{y} + z = 10 </s_latex_3><s_latex_4>\\sqrt{3 + z} = 10 </s_latex_4><s_latex_5>\\log_{4}(5 + z) </s_latex_5><s_latex_6>2x + 3 = y </s_latex_6><s_latex_7>\\log(x^2 + 3y) </s_latex_7><s_latex_8>\\lim_{x \\to 2} \\frac{x^2 - 4}{x - 2} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_4.jpg saved to generated_template_4.json\n",
            "<s><s><s> <s_latex_<unk>>\\epsilon = - \\frac { \\Delta + 2 } { \\Delta }</s_latex_<unk>><s_latex_2>C ^ { 1 } _ { 1 \\mu } = - C _ { 2 } _ { 2 \\mu } </s_latex_2><s_latex_3>C _ { 2 } = C _ { 3 } = - \\frac { 1 } { 2 } </s_latex_3><s_latex_4>\\Omega _ { 0 } = \\pi ^ { 0 } \\approx 0 ,</s_latex_4><s_latex_5>\\lim_{x \\to \\infty} \\frac{x^3 + x^2}{e^2} </s_latex_5><s_latex_6>\\lparen \\bar { S } , \\bar { S } \\rparen = 0 </s_latex_6><s_latex_7>E \\rightarrow B , B \\rightarrow - E </s_latex_7><s_latex_8>\\partial _ { 0 } A _ { 0 } = 0 ,</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_45.jpg saved to generated_template_45.json\n",
            "<s><s><s> <s_latex_<unk>><unk> O _ { e } ^ { 2 } - y</s_latex_<unk>><s_latex_2>\\lim_{x \\to \\infty} \\frac{\\logx}{x^2} </s_latex_2><s_latex_3>\\log_{10}(y + 1) </s_latex_3><s_latex_4>\\sqrt{x + y + z} = 5 </s_latex_4><s_latex_5>4e^{x + 3} </s_latex_5><s_latex_6>\\lim_{x \\to \\infty} \\frac{\\ln(x)}{x^2} </s_latex_6><s_latex_7>x^3 + \\sqrt{y} = z </s_latex_7><s_latex_8>x^3 - 2x + 1 = 0 </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_5.jpg saved to generated_template_5.json\n",
            "<s><s><s> <s_latex_<unk>>\\rho = \\sum _ { i } H _ { i } \\otimes h ^ { 2 } </s_latex_<unk>><s_latex_2>E = \\frac { e ^ { 2 } } { 2 p ^ { + } }</s_latex_2><s_latex_3>\\Delta F = q _ { 0 } \\sim \\xi ^ { N / 2 }</s_latex_3><s_latex_4>\\Delta p = - \\Delta \\dot { v } = - \\Delta V / v </s_latex_4><s_latex_5>\\oint _ { \\Sigma _ { I } B = 2 \\pi n ^ { I }</s_latex_5><s_latex_6>Y _ { N M } , M = 1 \\ldots K - 1 , N = 0 ,</s_latex_6><s_latex_7>X ^ { i } = \\xi ^ { i } , Z = X ^ { m } = 0 ,</s_latex_7><s_latex_8>F _ { + 1 2 3 } = \\mu , \\lparen \\mu \\neq 0 \\rparen</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_51.jpg saved to generated_template_51.json\n",
            "<s><s><s> <s_latex_<unk>>\\frac { 1 } { R } F ^ { i j } F _ { j 0 } </s_latex_<unk>><s_latex_2>L = \\frac { 1 } { 4 \\pi } \\alpha K d \\alpha ,</s_latex_2><s_latex_3>z = \\frac { \\omega \\tau } { 2 }</s_latex_3><s_latex_4>u ^ { 2 } \\equiv 2 r ^ { 2 } - \\zeta \\geq \\zeta </s_latex_4><s_latex_5>2e^{4y} </s_latex_5><s_latex_6>G = Q ^ { \\dagger } \\bar { G } Q ,</s_latex_6><s_latex_7>a _ { 0 , 1 , 2 , 3 } \\in R </s_latex_7><s_latex_8>\\frac { D \\rho } { \\partial L }</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_54.jpg saved to generated_template_54.json\n",
            "<s><s><s> <s_latex_<unk>>x^2 + \\frac { 1 } { y } = z^2</s_latex_<unk>><s_latex_2>x^2 + y + 2x^2 = 5 </s_latex_2><s_latex_3>\\lim_{x \\to 0} \\frac{\\sin(14x)}{x} </s_latex_3><s_latex_4>\\lim_{x \\to \\to 0} \\frac{x} </s_latex_4><s_latex_5>\\ddot { y } + z = 2x </s_latex_5><s_latex_6>\\lim_{x \\to \\infty} \\frac{5x^4 + x^2}{e^x} </s_latex_6><s_latex_7>x + y + z^2 = 7 </s_latex_7><s_latex_8>x^3 - 2x + 1 = 0 </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_6.jpg saved to generated_template_6.json\n",
            "<s><s><s> <s_latex_<unk>>\\Phi = - \\frac { 2 Y } { k } + c o n s t </s_latex_<unk>><s_latex_2>\\alpha _ { 2 } = \\sqrt { 2 } ,</s_latex_2><s_latex_3>\\bar { L } = - g \\cdot b + L + \\@cdots ,</s_latex_3><s_latex_4>\\kappa _ { B } - \\kappa _ { C } = 0 ,</s_latex_4><s_latex_5>F = - \\sqrt { a } \\phi ^ { \\ast } \\sigma ,</s_latex_5><s_latex_6>\\ln(2x - 3) </s_latex_6><s_latex_7>D _ { - } = i \\bar { \\partial }</s_latex_7><s_latex_8>\\delta \\psi _ { M } = D _ { M } \\eta = 0</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_63.jpg saved to generated_template_63.json\n",
            "<s><s><s> <s_latex_<unk>>\\lim_{x \\to \\infty} \\frac{5x^2 + x}{x^2 + 1} </s_latex_<unk>><s_latex_2>\\lim_{x \\to \\infty} \\frac{x^6 + 1} </s_latex_2><s_latex_3>\\frac{x^2 + 2}{y} + 1 = 0 </s_latex_3><s_latex_4>\\ln(4y + 2) </s_latex_4><s_latex_5>2x^2 + 5xy - \\psi = 0 </s_latex_5><s_latex_6>\\log_{10}(x^2 + 1) </s_latex_6><s_latex_7>x^3 + y^2 + z = 10 </s_latex_7><s_latex_8>\\lim_{x \\to \\infty} \\frac{x^4}{e^x} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_7.jpg saved to generated_template_7.json\n",
            "<s><s><s> <s_latex_<unk>>m v \\equiv P - \\mu \\times E</s_latex_<unk>><s_latex_2>M _ { a b } M _ { c b } = 6 a c ,</s_latex_2><s_latex_3>a c = q c a b d = q d b</s_latex_3><s_latex_4>x^3 - 2y + z^2 = 10 </s_latex_4><s_latex_5>\\theta _ { l } : t \\rightarrow 1 - t </s_latex_5><s_latex_6>\\epsilon = O ^ { + } </s_latex_6><s_latex_7>\\sin \\lambda = - \\frac { i \\rho } { 2 \\zeta } ,</s_latex_7><s_latex_8>r = \\frac { \\sqrt { 4 \\pi } } { \\beta } k </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_72.jpg saved to generated_template_72.json\n",
            "<s><s><s> <s_latex_<unk>>A U - i B V = U E ,</s_latex_<unk>><s_latex_2>p \\to m - p - 2 , \\phi \\to - \\phi </s_latex_2><s_latex_3>\\phi ^ { \\prime } = g ^ { - 1 } \\phi g </s_latex_3><s_latex_4>\\chi _ { \\mathrm { P H } } = \\eta </s_latex_4><s_latex_5>W _ { \\mu } \\cdot K = 0 </s_latex_5><s_latex_6>T \\rightarrow \\frac { 1 } { T } </s_latex_6><s_latex_7>\\lim_{x \\to 0} \\frac{\\ln(1 - x)}{x} </s_latex_7><s_latex_8>z = \\frac { \\omega \\tau } { 2 }</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_75.jpg saved to generated_template_75.json\n",
            "<s><s><s> <s_latex_<unk>>x^3 + y = 0 </s_latex_<unk>><s_latex_2>e^{x/s_latex_2} </s_latex_2><s_latex_3>2e^{-2x + 3} </s_latex_3><s_latex_4>\\lim_{x \\to 0} \\frac{\\sin(9x)}{x} </s_latex_4><s_latex_5>\\lim_{x \\to \\infty} \\frac{e^x}{x^2} </s_latex_5><s_latex_6>3x^2 + y + 2z = 0 </s_latex_6><s_latex_7>e^{x + 5y} </s_latex_7><s_latex_8>\\lim_{x \\to \\infty} \\frac{5x^4 + x^2}{e^x} </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_8.jpg saved to generated_template_8.json\n",
            "<s><s><s> <s_latex_<unk>>\\xi \\vert _ { \\partial M } = 0</s_latex_<unk>><s_latex_2>x^2 + y^2 + z^2 = 1 </s_latex_2><s_latex_3>8e^{2 - x} </s_latex_3><s_latex_4>\\# , z e r o \\space m o d e s = 2 N k ,</s_latex_4><s_latex_5>\\tau = \\frac { \\sqrt { 4 \\pi } } { \\beta } k </s_latex_5><s_latex_6>\\int \\Omega _ { K } = \\pi Q , Q \\in Z </s_latex_6><s_latex_7>F _ { i j } = \\epsilon _ { i j k } D _ { k } \\phi</s_latex_7><s_latex_8>I \\star \\psi = \\psi \\star I = \\psi</s_latex_8></s>\n",
            "Generated LaTeX for generated_template_843.jpg saved to generated_template_843.json\n",
            "<s><s><s> <s_latex_<unk>>\\psi \\rightarrow e ^ { i \\theta / 2 } \\psi </s_latex_<unk>><s_latex_2>g _ { m \\parallel } \\geq \\delta </s_latex_2><s_latex_3>e^{sqrt{x} </s_latex_3><s_latex_4>\\Phi ^ { 2 } = B ^ { - 1 } , K = C B - A ^ { 2 } </s_latex_4><s_latex_5>c = \\frac { 2 } { r _ { 0 } m _ { 0 } m _ { 0 } \\pi \\ll 1 </s_latex_5><s_latex_6><unk> 6 \\pi L = - e ^ { - K } R + \\ldots</s_latex_6><s_latex_7>\\sqrt{x} + 2y + z = 8 </s_latex_7><s_latex_8>L ^ { f } = \\lbrace \\nu , e \\rbrace </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_85.jpg saved to generated_template_85.json\n",
            "<s><s><s> <s_latex_<unk>>e^{2x} </s_latex_<unk>><s_latex_2>\\lim_{x \\to 0} \\frac{<unk> - \\cos x}{x^2} </s_latex_2><s_latex_3>e^{-3} \\sqrt{x} </s_latex_3><s_latex_4e^{x + 3} </s_latex_4><s_latex_5>\\log_{10}(x^2 + 1) </s_latex_5><s_latex_6>\\log_{10}(x^2 + 1) </s_latex_6><s_latex_7>4x + y + z = 1 4 </s_latex_7><s_latex_8>\\frac{x + y}{z} + z = 1 4 </s_latex_8></s>\n",
            "Generated LaTeX for generated_template_9.jpg saved to generated_template_9.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TED"
      ],
      "metadata": {
        "id": "CueOGBIzdnf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from donut import JSONParseEvaluator"
      ],
      "metadata": {
        "id": "zFVUIq77WZuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def strip_spaces(data):\n",
        "    \"\"\"\n",
        "    Recursively strip spaces from strings in a dictionary or list.\n",
        "    \"\"\"\n",
        "    if isinstance(data, dict):\n",
        "        return {k.strip(): strip_spaces(v) if isinstance(v, (dict, list)) else v.strip() if isinstance(v, str) else v for k, v in data.items()}\n",
        "    elif isinstance(data, list):\n",
        "        return [strip_spaces(item) for item in data]\n",
        "    return data\n",
        "\n",
        "def TED_Evaluation(Json_GT_Path, Json_Predicted_Path):\n",
        "    all_scores = []\n",
        "    for x in [x for x in os.listdir(Json_GT_Path) if x.endswith('.json')]:\n",
        "        gt_file_path = os.path.join(Json_GT_Path, x)\n",
        "        pred_file_path = os.path.join(Json_Predicted_Path, x)\n",
        "\n",
        "        if os.path.exists(gt_file_path) and os.path.exists(pred_file_path):\n",
        "            with open(gt_file_path) as f1, open(pred_file_path) as f2:\n",
        "                data1 = json.load(f1)\n",
        "                data2 = json.load(f2)\n",
        "\n",
        "                # Remove spaces in keys and string values\n",
        "                data1 = strip_spaces(data1)\n",
        "                data2 = strip_spaces(data2)\n",
        "\n",
        "                evaluator = JSONParseEvaluator()\n",
        "                score = evaluator.cal_acc(data1, data2)\n",
        "                print(x, \":\", score)\n",
        "                all_scores.append(score)\n",
        "        else:\n",
        "            print(f\"File not found: {x}\")\n",
        "\n",
        "    if all_scores:\n",
        "        print(sum(all_scores))\n",
        "        print(len(all_scores))\n",
        "        print(\"Average Score: \", sum(all_scores) / len(all_scores))\n",
        "    else:\n",
        "        print(\"No scores calculated.\")\n"
      ],
      "metadata": {
        "id": "9EfC5gUUd4DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor.save_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\checkpoint-800\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWsmynWqnRmj",
        "outputId": "dbf66091-7937-4024-eedf-6c3851981c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Donut on Final dataset test\n",
        "\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\Final_Test_Dataset\\donut_output\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\Final_Test_Dataset\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1-i8iHxmqvb",
        "outputId": "bdbbbd68-4df8-4acc-cd41-d725b5de4bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_template_1.json : 0.9375\n",
            "generated_template_10.json : 0.8792270531400966\n",
            "generated_template_1079.json : 0.952076677316294\n",
            "generated_template_1093.json : 0.9847094801223242\n",
            "generated_template_11.json : 0.9893048128342246\n",
            "generated_template_1118.json : 0.9736842105263158\n",
            "generated_template_116.json : 0.9684542586750788\n",
            "generated_template_12.json : 0.9078947368421053\n",
            "generated_template_129.json : 0.9362416107382551\n",
            "generated_template_13.json : 0.8698224852071006\n",
            "generated_template_14.json : 0.9675925925925926\n",
            "generated_template_15.json : 0.9329608938547486\n",
            "generated_template_16.json : 0.9731182795698925\n",
            "generated_template_17.json : 0.9245283018867925\n",
            "generated_template_171.json : 0.9357142857142857\n",
            "generated_template_18.json : 0.9415584415584416\n",
            "generated_template_19.json : 0.9651162790697675\n",
            "generated_template_2.json : 0.9615384615384616\n",
            "generated_template_20.json : 0.8036363636363637\n",
            "generated_template_200.json : 0.9913793103448276\n",
            "generated_template_233.json : 0.9330855018587361\n",
            "generated_template_293.json : 0.9194139194139194\n",
            "generated_template_3.json : 0.915\n",
            "generated_template_346.json : 0.9434523809523809\n",
            "generated_template_355.json : 0.9480968858131488\n",
            "generated_template_4.json : 0.8827586206896552\n",
            "generated_template_45.json : 0.96996996996997\n",
            "generated_template_5.json : 0.8789473684210526\n",
            "generated_template_51.json : 0.9504132231404958\n",
            "generated_template_54.json : 0.948339483394834\n",
            "generated_template_6.json : 0.8038277511961722\n",
            "generated_template_63.json : 0.992831541218638\n",
            "generated_template_7.json : 0.9112149532710281\n",
            "generated_template_72.json : 0.8976377952755905\n",
            "generated_template_75.json : 0.9601593625498008\n",
            "generated_template_8.json : 0.9562841530054644\n",
            "generated_template_843.json : 0.9296296296296296\n",
            "generated_template_85.json : 0.8972602739726028\n",
            "generated_template_9.json : 0.815068493150685\n",
            "36.24944984209177\n",
            "39\n",
            "Average Score:  0.9294730728741479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Donut on Final dataset test\n",
        "\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\Final_Test_Dataset\\donut_output\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\Final_Test_Dataset\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpGZHUUoFwa-",
        "outputId": "63720d3c-f0fd-45a4-cb0d-75cdf03d9e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_template_1.json : 0.9375\n",
            "generated_template_10.json : 0.8792270531400966\n",
            "generated_template_1079.json : 0.952076677316294\n",
            "generated_template_1093.json : 0.9847094801223242\n",
            "generated_template_11.json : 0.9893048128342246\n",
            "generated_template_1118.json : 0.9736842105263158\n",
            "generated_template_116.json : 0.9684542586750788\n",
            "generated_template_12.json : 0.9078947368421053\n",
            "generated_template_129.json : 0.9362416107382551\n",
            "generated_template_13.json : 0.8698224852071006\n",
            "generated_template_14.json : 0.9675925925925926\n",
            "generated_template_15.json : 0.9329608938547486\n",
            "generated_template_16.json : 0.9731182795698925\n",
            "generated_template_17.json : 0.9245283018867925\n",
            "generated_template_171.json : 0.9357142857142857\n",
            "generated_template_18.json : 0.9415584415584416\n",
            "generated_template_19.json : 0.9651162790697675\n",
            "generated_template_2.json : 0.9615384615384616\n",
            "generated_template_20.json : 0.8036363636363637\n",
            "generated_template_200.json : 0.9913793103448276\n",
            "generated_template_233.json : 0.9330855018587361\n",
            "generated_template_293.json : 0.9194139194139194\n",
            "generated_template_3.json : 0.915\n",
            "generated_template_346.json : 0.9434523809523809\n",
            "generated_template_355.json : 0.9480968858131488\n",
            "generated_template_4.json : 0.8827586206896552\n",
            "generated_template_45.json : 0.96996996996997\n",
            "generated_template_5.json : 0.8789473684210526\n",
            "generated_template_51.json : 0.9504132231404958\n",
            "generated_template_54.json : 0.948339483394834\n",
            "generated_template_6.json : 0.8038277511961722\n",
            "generated_template_63.json : 0.992831541218638\n",
            "generated_template_7.json : 0.9112149532710281\n",
            "generated_template_72.json : 0.8976377952755905\n",
            "generated_template_75.json : 0.9601593625498008\n",
            "generated_template_8.json : 0.9562841530054644\n",
            "generated_template_843.json : 0.9296296296296296\n",
            "generated_template_85.json : 0.8972602739726028\n",
            "generated_template_9.json : 0.815068493150685\n",
            "36.24944984209177\n",
            "39\n",
            "Average Score:  0.9294730728741479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Donut on Final dataset test\n",
        "\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\generated_dataset\\donut_output\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\Iamlatex2B\\generated_dataset\\Test\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZXpUg_u6Bs1",
        "outputId": "5a7a9c48-695d-412a-ed48-b181ad255592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_template_1006.json : 0.8801261829652997\n",
            "generated_template_1017.json : 0.9567901234567902\n",
            "generated_template_1019.json : 0.8540925266903915\n",
            "generated_template_1021.json : 0.9088050314465409\n",
            "generated_template_103.json : 0.9022346368715084\n",
            "generated_template_1036.json : 0.9111747851002865\n",
            "generated_template_1049.json : 0.9169675090252708\n",
            "generated_template_1051.json : 0.9473684210526316\n",
            "generated_template_1071.json : 0.9607142857142857\n",
            "generated_template_1072.json : 0.9457142857142857\n",
            "generated_template_1074.json : 0.9622641509433962\n",
            "generated_template_1079.json : 0.952076677316294\n",
            "generated_template_109.json : 0.9136904761904762\n",
            "generated_template_1093.json : 0.9847094801223242\n",
            "generated_template_1109.json : 0.9237057220708447\n",
            "generated_template_111.json : 0.973134328358209\n",
            "generated_template_1117.json : 0.9230769230769231\n",
            "generated_template_1118.json : 0.9736842105263158\n",
            "generated_template_1121.json : 0.9540229885057472\n",
            "generated_template_1127.json : 0.9107692307692308\n",
            "generated_template_1133.json : 0.9283276450511946\n",
            "generated_template_1147.json : 0.9595588235294118\n",
            "generated_template_1153.json : 0.9177631578947368\n",
            "generated_template_116.json : 0.9684542586750788\n",
            "generated_template_1160.json : 0.9706840390879479\n",
            "generated_template_1171.json : 0.9595015576323987\n",
            "generated_template_1175.json : 0.9372937293729373\n",
            "generated_template_129.json : 0.9362416107382551\n",
            "generated_template_13.json : 0.95578231292517\n",
            "generated_template_17.json : 0.9464788732394366\n",
            "generated_template_171.json : 0.9357142857142857\n",
            "generated_template_197.json : 0.8996865203761756\n",
            "generated_template_200.json : 0.9913793103448276\n",
            "generated_template_209.json : 0.9425981873111783\n",
            "generated_template_225.json : 0.9736842105263158\n",
            "generated_template_233.json : 0.9330855018587361\n",
            "generated_template_243.json : 0.9827586206896551\n",
            "generated_template_244.json : 0.9936708860759493\n",
            "generated_template_248.json : 0.9480968858131488\n",
            "generated_template_250.json : 0.9808306709265175\n",
            "generated_template_254.json : 0.8037735849056604\n",
            "generated_template_262.json : 0.8981818181818182\n",
            "generated_template_263.json : 0.9680511182108626\n",
            "generated_template_268.json : 0.9372937293729373\n",
            "generated_template_274.json : 0.9807692307692307\n",
            "generated_template_279.json : 0.98125\n",
            "generated_template_292.json : 0.9570552147239264\n",
            "generated_template_293.json : 0.9194139194139194\n",
            "generated_template_300.json : 0.9015384615384615\n",
            "generated_template_306.json : 0.984472049689441\n",
            "generated_template_324.json : 0.9868421052631579\n",
            "generated_template_345.json : 0.9766081871345029\n",
            "generated_template_346.json : 0.9434523809523809\n",
            "generated_template_355.json : 0.9480968858131488\n",
            "generated_template_358.json : 0.861878453038674\n",
            "generated_template_365.json : 0.9204152249134948\n",
            "generated_template_382.json : 0.9419795221843004\n",
            "generated_template_390.json : 0.9228486646884273\n",
            "generated_template_416.json : 0.923943661971831\n",
            "generated_template_45.json : 0.96996996996997\n",
            "generated_template_471.json : 0.9470404984423676\n",
            "generated_template_473.json : 0.9539877300613497\n",
            "generated_template_486.json : 0.9455128205128205\n",
            "generated_template_502.json : 0.9627507163323782\n",
            "generated_template_51.json : 0.9504132231404958\n",
            "generated_template_515.json : 0.9650793650793651\n",
            "generated_template_520.json : 0.9803921568627451\n",
            "generated_template_529.json : 0.9306930693069306\n",
            "generated_template_54.json : 0.948339483394834\n",
            "generated_template_555.json : 0.9421221864951769\n",
            "generated_template_558.json : 0.934375\n",
            "generated_template_565.json : 0.9456869009584664\n",
            "generated_template_587.json : 0.9565217391304348\n",
            "generated_template_593.json : 0.9630681818181818\n",
            "generated_template_615.json : 0.9477124183006536\n",
            "generated_template_622.json : 0.973421926910299\n",
            "generated_template_63.json : 0.992831541218638\n",
            "generated_template_642.json : 0.9311475409836065\n",
            "generated_template_643.json : 0.9875389408099688\n",
            "generated_template_648.json : 0.9819819819819819\n",
            "generated_template_649.json : 0.9496644295302014\n",
            "generated_template_658.json : 0.9555555555555556\n",
            "generated_template_659.json : 0.9873015873015873\n",
            "generated_template_660.json : 0.9063545150501673\n",
            "generated_template_678.json : 0.9352112676056338\n",
            "generated_template_689.json : 0.965625\n",
            "generated_template_69.json : 0.9693251533742331\n",
            "generated_template_698.json : 0.9457627118644067\n",
            "generated_template_699.json : 0.9688715953307393\n",
            "generated_template_713.json : 0.939297124600639\n",
            "generated_template_719.json : 0.9782608695652174\n",
            "generated_template_72.json : 0.8976377952755905\n",
            "generated_template_740.json : 0.9178470254957507\n",
            "generated_template_746.json : 0.9244186046511628\n",
            "generated_template_747.json : 0.9579579579579579\n",
            "generated_template_75.json : 0.9601593625498008\n",
            "generated_template_781.json : 0.9298245614035088\n",
            "generated_template_789.json : 0.9765395894428153\n",
            "generated_template_793.json : 0.8900709219858156\n",
            "generated_template_795.json : 0.9566473988439307\n",
            "generated_template_812.json : 0.9598765432098766\n",
            "generated_template_824.json : 0.9821958456973294\n",
            "generated_template_826.json : 0.947945205479452\n",
            "generated_template_843.json : 0.9296296296296296\n",
            "generated_template_85.json : 0.8972602739726028\n",
            "generated_template_856.json : 0.9880239520958084\n",
            "generated_template_861.json : 0.9753521126760564\n",
            "generated_template_865.json : 0.9657320872274143\n",
            "generated_template_869.json : 0.9518900343642611\n",
            "generated_template_877.json : 0.9473684210526316\n",
            "generated_template_887.json : 0.9744318181818182\n",
            "generated_template_917.json : 0.9498525073746312\n",
            "generated_template_919.json : 0.9114285714285715\n",
            "generated_template_933.json : 0.9858657243816255\n",
            "generated_template_946.json : 0.9669669669669669\n",
            "generated_template_947.json : 0.8565891472868217\n",
            "generated_template_95.json : 0.8654545454545455\n",
            "generated_template_96.json : 0.9866220735785953\n",
            "generated_template_980.json : 0.9335548172757475\n",
            "generated_template_995.json : 0.9300411522633745\n",
            "generated_template_998.json : 0.9535603715170279\n",
            "114.35713949667674\n",
            "121\n",
            "Average Score:  0.945100326418816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Donut on Iam2latex2 dataset test\n",
        "\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\output\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_dC-T7GVD6Q",
        "outputId": "536fa8cc-192a-45ec-dd78-2a7e6e50a259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_template_106.json : 0.9525316455696202\n",
            "generated_template_129.json : 0.9348534201954397\n",
            "generated_template_131.json : 0.8958333333333334\n",
            "generated_template_155.json : 0.9369085173501577\n",
            "generated_template_157.json : 0.8878205128205128\n",
            "generated_template_158.json : 0.9169139465875371\n",
            "generated_template_16.json : 0.8671328671328671\n",
            "generated_template_162.json : 0.9314641744548287\n",
            "generated_template_169.json : 0.9416666666666667\n",
            "generated_template_17.json : 0.9312977099236641\n",
            "generated_template_174.json : 0.8773584905660378\n",
            "generated_template_179.json : 0.9504643962848297\n",
            "generated_template_188.json : 0.9426751592356688\n",
            "generated_template_221.json : 0.9525423728813559\n",
            "generated_template_236.json : 0.8895522388059701\n",
            "generated_template_238.json : 0.8745762711864407\n",
            "generated_template_243.json : 0.9051490514905149\n",
            "generated_template_244.json : 0.8932926829268293\n",
            "generated_template_25.json : 0.8629283489096573\n",
            "generated_template_26.json : 0.954248366013072\n",
            "generated_template_267.json : 0.85625\n",
            "generated_template_268.json : 0.9230769230769231\n",
            "generated_template_269.json : 0.9020771513353116\n",
            "generated_template_28.json : 0.8256227758007118\n",
            "generated_template_281.json : 0.941358024691358\n",
            "generated_template_282.json : 0.8820224719101124\n",
            "generated_template_303.json : 0.8963414634146342\n",
            "generated_template_305.json : 0.9044776119402985\n",
            "generated_template_310.json : 0.8942307692307693\n",
            "generated_template_33.json : 0.9382716049382716\n",
            "generated_template_341.json : 0.9329268292682926\n",
            "generated_template_346.json : 0.9791666666666666\n",
            "generated_template_349.json : 0.8900709219858156\n",
            "generated_template_356.json : 0.9593220338983051\n",
            "generated_template_365.json : 0.8929765886287625\n",
            "generated_template_377.json : 0.8771929824561404\n",
            "generated_template_378.json : 0.9020771513353116\n",
            "generated_template_383.json : 0.8939393939393939\n",
            "generated_template_389.json : 0.9290322580645162\n",
            "generated_template_394.json : 0.8678678678678678\n",
            "generated_template_395.json : 0.8947368421052632\n",
            "generated_template_40.json : 0.9174917491749175\n",
            "generated_template_403.json : 0.9322033898305084\n",
            "generated_template_409.json : 0.9230769230769231\n",
            "generated_template_412.json : 0.9036544850498339\n",
            "generated_template_418.json : 0.9325513196480939\n",
            "generated_template_422.json : 0.8878504672897196\n",
            "generated_template_428.json : 0.8694158075601375\n",
            "generated_template_43.json : 0.9197707736389684\n",
            "generated_template_438.json : 0.8219584569732937\n",
            "generated_template_44.json : 0.8679867986798679\n",
            "generated_template_477.json : 0.8837209302325582\n",
            "generated_template_487.json : 0.9082278481012658\n",
            "generated_template_49.json : 0.935483870967742\n",
            "generated_template_498.json : 0.9457831325301205\n",
            "generated_template_502.json : 0.9739413680781759\n",
            "generated_template_508.json : 0.9049079754601227\n",
            "generated_template_512.json : 0.9333333333333333\n",
            "generated_template_519.json : 0.8301282051282051\n",
            "generated_template_525.json : 0.929368029739777\n",
            "generated_template_528.json : 0.9140127388535032\n",
            "generated_template_540.json : 0.909433962264151\n",
            "generated_template_544.json : 0.9142011834319527\n",
            "generated_template_545.json : 0.9161073825503355\n",
            "generated_template_547.json : 0.9700598802395209\n",
            "generated_template_565.json : 0.9207317073170732\n",
            "generated_template_575.json : 0.9247648902821317\n",
            "generated_template_579.json : 0.9346153846153846\n",
            "generated_template_58.json : 0.8790849673202614\n",
            "generated_template_581.json : 0.9208211143695014\n",
            "generated_template_582.json : 0.9050445103857567\n",
            "generated_template_602.json : 0.9484536082474226\n",
            "generated_template_609.json : 0.9299363057324841\n",
            "generated_template_61.json : 0.9083094555873925\n",
            "generated_template_616.json : 0.9073482428115016\n",
            "generated_template_642.json : 0.9046242774566474\n",
            "generated_template_643.json : 0.8344827586206897\n",
            "generated_template_649.json : 0.9166666666666666\n",
            "generated_template_673.json : 0.8535825545171339\n",
            "generated_template_684.json : 0.944954128440367\n",
            "generated_template_694.json : 0.8430769230769231\n",
            "generated_template_704.json : 0.7993920972644377\n",
            "generated_template_708.json : 0.8758389261744967\n",
            "generated_template_724.json : 0.8827160493827161\n",
            "generated_template_73.json : 0.8863636363636364\n",
            "generated_template_731.json : 0.8606060606060606\n",
            "generated_template_755.json : 0.876056338028169\n",
            "generated_template_764.json : 0.9319526627218935\n",
            "generated_template_773.json : 0.9404388714733543\n",
            "generated_template_776.json : 0.9494949494949495\n",
            "generated_template_777.json : 0.883495145631068\n",
            "generated_template_79.json : 0.9318181818181819\n",
            "generated_template_8.json : 0.93125\n",
            "generated_template_807.json : 0.9457831325301205\n",
            "generated_template_812.json : 0.8881789137380192\n",
            "generated_template_814.json : 0.9090909090909091\n",
            "generated_template_826.json : 0.8628571428571429\n",
            "generated_template_831.json : 0.8722044728434505\n",
            "generated_template_88.json : 0.8820058997050148\n",
            "generated_template_93.json : 0.9365994236311239\n",
            "90.64955882552484\n",
            "100\n",
            "Average Score:  0.9064955882552483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "66"
      ],
      "metadata": {
        "id": "LLDjWUtRVJSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "047An-_jVJOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7Hyw8bdVJMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2uHSeiEVJKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate test\n",
        "\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\output\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "id": "VUkmtsWVzYAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with FW\n",
        "\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\output\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU7vZf-ld6iV",
        "outputId": "c8922658-157d-48e0-e3af-daa1b5ee8a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_template_106.json : 0.9359756097560976\n",
            "generated_template_129.json : 0.9415384615384615\n",
            "generated_template_131.json : 0.9528023598820059\n",
            "generated_template_155.json : 0.9270516717325228\n",
            "generated_template_157.json : 0.8313253012048193\n",
            "generated_template_158.json : 0.9256198347107438\n",
            "generated_template_16.json : 0.9228295819935691\n",
            "generated_template_162.json : 0.924198250728863\n",
            "generated_template_169.json : 0.9278074866310161\n",
            "generated_template_17.json : 0.8827838827838828\n",
            "generated_template_174.json : 0.8835820895522388\n",
            "generated_template_179.json : 0.9584569732937686\n",
            "generated_template_188.json : 0.9066265060240963\n",
            "generated_template_221.json : 0.9255663430420712\n",
            "generated_template_236.json : 0.9567901234567902\n",
            "generated_template_238.json : 0.9381107491856677\n",
            "generated_template_243.json : 0.6839378238341969\n",
            "generated_template_244.json : 0.8738738738738738\n",
            "generated_template_25.json : 0.881619937694704\n",
            "generated_template_26.json : 0.95625\n",
            "generated_template_267.json : 0.75625\n",
            "generated_template_268.json : 0.9379084967320261\n",
            "generated_template_269.json : 0.9380530973451328\n",
            "generated_template_28.json : 0.889967637540453\n",
            "generated_template_281.json : 0.9473684210526316\n",
            "generated_template_282.json : 0.865546218487395\n",
            "generated_template_303.json : 0.9277456647398844\n",
            "generated_template_305.json : 0.8439306358381503\n",
            "generated_template_310.json : 0.9064516129032258\n",
            "generated_template_33.json : 0.943217665615142\n",
            "generated_template_341.json : 0.9\n",
            "generated_template_346.json : 0.9649122807017544\n",
            "generated_template_349.json : 0.9207920792079208\n",
            "generated_template_356.json : 0.898360655737705\n",
            "generated_template_365.json : 0.9290123456790124\n",
            "generated_template_377.json : 0.8192090395480226\n",
            "generated_template_378.json : 0.9264705882352942\n",
            "generated_template_383.json : 0.8294117647058823\n",
            "generated_template_389.json : 0.9090909090909091\n",
            "generated_template_394.json : 0.907563025210084\n",
            "generated_template_395.json : 0.8538011695906433\n",
            "generated_template_40.json : 0.9240506329113924\n",
            "generated_template_403.json : 0.9111111111111111\n",
            "generated_template_409.json : 0.9166666666666666\n",
            "generated_template_412.json : 0.9012738853503185\n",
            "generated_template_418.json : 0.8473053892215568\n",
            "generated_template_422.json : 0.8757396449704142\n",
            "generated_template_428.json : 0.9320388349514563\n",
            "generated_template_43.json : 0.9413333333333334\n",
            "generated_template_438.json : 0.888235294117647\n",
            "generated_template_44.json : 0.8142414860681114\n",
            "generated_template_477.json : 0.9101449275362319\n",
            "generated_template_487.json : 0.9040697674418605\n",
            "generated_template_49.json : 0.9577464788732395\n",
            "generated_template_498.json : 0.9117647058823529\n",
            "generated_template_502.json : 0.9238095238095239\n",
            "generated_template_508.json : 0.9285714285714286\n",
            "generated_template_512.json : 0.8609271523178808\n",
            "generated_template_519.json : 0.922077922077922\n",
            "generated_template_525.json : 0.9321428571428572\n",
            "generated_template_528.json : 0.9503105590062112\n",
            "generated_template_540.json : 0.8788927335640139\n",
            "generated_template_544.json : 0.9142011834319527\n",
            "generated_template_545.json : 0.9555555555555556\n",
            "generated_template_547.json : 0.9678362573099415\n",
            "generated_template_565.json : 0.9047619047619048\n",
            "generated_template_575.json : 0.9235474006116208\n",
            "generated_template_579.json : 0.8884758364312267\n",
            "generated_template_58.json : 0.9177215189873418\n",
            "generated_template_581.json : 0.9008746355685131\n",
            "generated_template_582.json : 0.8947368421052632\n",
            "generated_template_602.json : 0.9570957095709571\n",
            "generated_template_609.json : 0.9492063492063492\n",
            "generated_template_61.json : 0.8679775280898876\n",
            "generated_template_616.json : 0.9123867069486404\n",
            "generated_template_642.json : 0.9005681818181819\n",
            "generated_template_643.json : 0.890728476821192\n",
            "generated_template_649.json : 0.896774193548387\n",
            "generated_template_673.json : 0.8672566371681416\n",
            "generated_template_684.json : 0.9446064139941691\n",
            "generated_template_694.json : 0.8614958448753463\n",
            "generated_template_704.json : 0.7462686567164178\n",
            "generated_template_708.json : 0.7981072555205048\n",
            "generated_template_724.json : 0.930635838150289\n",
            "generated_template_73.json : 0.7941176470588236\n",
            "generated_template_731.json : 0.7020057306590257\n",
            "generated_template_755.json : 0.8840579710144928\n",
            "generated_template_764.json : 0.9224137931034483\n",
            "generated_template_773.json : 0.9446153846153846\n",
            "generated_template_776.json : 0.9228295819935691\n",
            "generated_template_777.json : 0.7857142857142857\n",
            "generated_template_79.json : 0.7987804878048781\n",
            "generated_template_8.json : 0.9373134328358209\n",
            "generated_template_807.json : 0.9485714285714286\n",
            "generated_template_812.json : 0.8764705882352941\n",
            "generated_template_814.json : 0.8237082066869301\n",
            "generated_template_826.json : 0.8379120879120879\n",
            "generated_template_831.json : 0.9302325581395349\n",
            "generated_template_88.json : 0.8430769230769231\n",
            "generated_template_93.json : 0.8895027624309393\n",
            "89.61640630085085\n",
            "100\n",
            "Average Score:  0.8961640630085086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model.save_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\FW\")\n",
        "# processor.save_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\FW\")"
      ],
      "metadata": {
        "id": "FQOkc49mfGpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with 2000 checkpoint\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\output\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDd535-mf9Y9",
        "outputId": "c8081c3e-6326-4adf-e1ec-ffbf06c83a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_template_106.json : 0.9298780487804879\n",
            "generated_template_129.json : 0.8953846153846154\n",
            "generated_template_131.json : 0.8997050147492626\n",
            "generated_template_155.json : 0.9604863221884499\n",
            "generated_template_157.json : 0.9457831325301205\n",
            "generated_template_158.json : 0.9090909090909091\n",
            "generated_template_16.json : 0.887459807073955\n",
            "generated_template_162.json : 0.9212827988338192\n",
            "generated_template_169.json : 0.9251336898395722\n",
            "generated_template_17.json : 0.9413919413919414\n",
            "generated_template_174.json : 0.9194029850746268\n",
            "generated_template_179.json : 0.9614243323442137\n",
            "generated_template_188.json : 0.9427710843373494\n",
            "generated_template_221.json : 0.9352750809061489\n",
            "generated_template_236.json : 0.9598765432098766\n",
            "generated_template_238.json : 0.9413680781758957\n",
            "generated_template_243.json : 0.8730569948186528\n",
            "generated_template_244.json : 0.8408408408408409\n",
            "generated_template_25.json : 0.8785046728971962\n",
            "generated_template_26.json : 0.95625\n",
            "generated_template_267.json : 0.88125\n",
            "generated_template_268.json : 0.9150326797385621\n",
            "generated_template_269.json : 0.8997050147492626\n",
            "generated_template_28.json : 0.8640776699029127\n",
            "generated_template_281.json : 0.935672514619883\n",
            "generated_template_282.json : 0.9355742296918768\n",
            "generated_template_303.json : 0.9190751445086706\n",
            "generated_template_305.json : 0.6734104046242775\n",
            "generated_template_310.json : 0.9483870967741935\n",
            "generated_template_33.json : 0.9400630914826499\n",
            "generated_template_341.json : 0.9171428571428571\n",
            "generated_template_346.json : 0.9415204678362573\n",
            "generated_template_349.json : 0.9405940594059405\n",
            "generated_template_356.json : 0.9508196721311475\n",
            "generated_template_365.json : 0.9290123456790124\n",
            "generated_template_377.json : 0.884180790960452\n",
            "generated_template_378.json : 0.9264705882352942\n",
            "generated_template_383.json : 0.8852941176470588\n",
            "generated_template_389.json : 0.8993506493506493\n",
            "generated_template_394.json : 0.9215686274509804\n",
            "generated_template_395.json : 0.9385964912280702\n",
            "generated_template_40.json : 0.9208860759493671\n",
            "generated_template_403.json : 0.9238095238095239\n",
            "generated_template_409.json : 0.9226190476190477\n",
            "generated_template_412.json : 0.9012738853503185\n",
            "generated_template_418.json : 0.9131736526946108\n",
            "generated_template_422.json : 0.9349112426035503\n",
            "generated_template_428.json : 0.9385113268608414\n",
            "generated_template_43.json : 0.9146666666666666\n",
            "generated_template_438.json : 0.8735294117647059\n",
            "generated_template_44.json : 0.8544891640866873\n",
            "generated_template_477.json : 0.936231884057971\n",
            "generated_template_487.json : 0.9534883720930233\n",
            "generated_template_49.json : 0.9605633802816902\n",
            "generated_template_498.json : 0.9558823529411765\n",
            "generated_template_502.json : 0.9746031746031746\n",
            "generated_template_508.json : 0.9047619047619048\n",
            "generated_template_512.json : 0.9105960264900662\n",
            "generated_template_519.json : 0.8831168831168831\n",
            "generated_template_525.json : 0.9214285714285715\n",
            "generated_template_528.json : 0.9099378881987578\n",
            "generated_template_540.json : 0.7854671280276817\n",
            "generated_template_544.json : 0.8875739644970414\n",
            "generated_template_545.json : 0.9206349206349207\n",
            "generated_template_547.json : 0.9532163742690059\n",
            "generated_template_565.json : 0.8809523809523809\n",
            "generated_template_575.json : 0.9296636085626911\n",
            "generated_template_579.json : 0.9144981412639406\n",
            "generated_template_58.json : 0.939873417721519\n",
            "generated_template_581.json : 0.9533527696793003\n",
            "generated_template_582.json : 0.7700831024930748\n",
            "generated_template_602.json : 0.9570957095709571\n",
            "generated_template_609.json : 0.946031746031746\n",
            "generated_template_61.json : 0.9382022471910112\n",
            "generated_template_616.json : 0.9093655589123867\n",
            "generated_template_642.json : 0.8977272727272727\n",
            "generated_template_643.json : 0.8774834437086093\n",
            "generated_template_649.json : 0.8870967741935484\n",
            "generated_template_673.json : 0.8672566371681416\n",
            "generated_template_684.json : 0.9475218658892128\n",
            "generated_template_694.json : 0.8919667590027701\n",
            "generated_template_704.json : 0.835820895522388\n",
            "generated_template_708.json : 0.8580441640378549\n",
            "generated_template_724.json : 0.8352601156069364\n",
            "generated_template_73.json : 0.8594771241830066\n",
            "generated_template_731.json : 0.9283667621776505\n",
            "generated_template_755.json : 0.9565217391304348\n",
            "generated_template_764.json : 0.9425287356321839\n",
            "generated_template_773.json : 0.9415384615384615\n",
            "generated_template_776.json : 0.9517684887459807\n",
            "generated_template_777.json : 0.8664596273291926\n",
            "generated_template_79.json : 0.9420731707317073\n",
            "generated_template_8.json : 0.8507462686567164\n",
            "generated_template_807.json : 0.3142857142857143\n",
            "generated_template_812.json : 0.8764705882352941\n",
            "generated_template_814.json : 0.8662613981762918\n",
            "generated_template_826.json : 0.8598901098901099\n",
            "generated_template_831.json : 0.8895348837209303\n",
            "generated_template_88.json : 0.8707692307692307\n",
            "generated_template_93.json : 0.9502762430939227\n",
            "90.3308033849677\n",
            "100\n",
            "Average Score:  0.903308033849677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with 2200 checkpoint\n",
        "model_output_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\"\n",
        "GT_Json_Path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\output\"\n",
        "\n",
        "TED_Evaluation(GT_Json_Path, model_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzGyf--UhS8U",
        "outputId": "e90d09c7-7eb7-4d29-ddfa-0c5f60bfa268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated_template_106.json : 0.9542682926829268\n",
            "generated_template_129.json : 0.9384615384615385\n",
            "generated_template_131.json : 0.8967551622418879\n",
            "generated_template_155.json : 0.939209726443769\n",
            "generated_template_157.json : 0.8945783132530121\n",
            "generated_template_158.json : 0.9228650137741047\n",
            "generated_template_16.json : 0.8778135048231511\n",
            "generated_template_162.json : 0.935860058309038\n",
            "generated_template_169.json : 0.9438502673796791\n",
            "generated_template_17.json : 0.9340659340659341\n",
            "generated_template_174.json : 0.8835820895522388\n",
            "generated_template_179.json : 0.9525222551928784\n",
            "generated_template_188.json : 0.9457831325301205\n",
            "generated_template_221.json : 0.9546925566343042\n",
            "generated_template_236.json : 0.8858024691358025\n",
            "generated_template_238.json : 0.8794788273615635\n",
            "generated_template_243.json : 0.9093264248704663\n",
            "generated_template_244.json : 0.8948948948948949\n",
            "generated_template_25.json : 0.8629283489096573\n",
            "generated_template_26.json : 0.95625\n",
            "generated_template_267.json : 0.85625\n",
            "generated_template_268.json : 0.9248366013071896\n",
            "generated_template_269.json : 0.9026548672566371\n",
            "generated_template_28.json : 0.8414239482200647\n",
            "generated_template_281.json : 0.9444444444444444\n",
            "generated_template_282.json : 0.8823529411764706\n",
            "generated_template_303.json : 0.9017341040462428\n",
            "generated_template_305.json : 0.9075144508670521\n",
            "generated_template_310.json : 0.8935483870967742\n",
            "generated_template_33.json : 0.9369085173501577\n",
            "generated_template_341.json : 0.9371428571428572\n",
            "generated_template_346.json : 0.97953216374269\n",
            "generated_template_349.json : 0.8976897689768977\n",
            "generated_template_356.json : 0.9606557377049181\n",
            "generated_template_365.json : 0.9012345679012346\n",
            "generated_template_377.json : 0.8813559322033898\n",
            "generated_template_378.json : 0.9029411764705882\n",
            "generated_template_383.json : 0.8970588235294118\n",
            "generated_template_389.json : 0.9285714285714286\n",
            "generated_template_394.json : 0.876750700280112\n",
            "generated_template_395.json : 0.8947368421052632\n",
            "generated_template_40.json : 0.9208860759493671\n",
            "generated_template_403.json : 0.9365079365079365\n",
            "generated_template_409.json : 0.9285714285714286\n",
            "generated_template_412.json : 0.9076433121019108\n",
            "generated_template_418.json : 0.9311377245508982\n",
            "generated_template_422.json : 0.893491124260355\n",
            "generated_template_428.json : 0.8770226537216829\n",
            "generated_template_43.json : 0.9253333333333333\n",
            "generated_template_438.json : 0.8235294117647058\n",
            "generated_template_44.json : 0.8761609907120743\n",
            "generated_template_477.json : 0.8840579710144928\n",
            "generated_template_487.json : 0.9156976744186046\n",
            "generated_template_49.json : 0.9380281690140845\n",
            "generated_template_498.json : 0.9470588235294117\n",
            "generated_template_502.json : 0.9746031746031746\n",
            "generated_template_508.json : 0.9077380952380952\n",
            "generated_template_512.json : 0.9370860927152318\n",
            "generated_template_519.json : 0.827922077922078\n",
            "generated_template_525.json : 0.9321428571428572\n",
            "generated_template_528.json : 0.9161490683229814\n",
            "generated_template_540.json : 0.9169550173010381\n",
            "generated_template_544.json : 0.9142011834319527\n",
            "generated_template_545.json : 0.9206349206349207\n",
            "generated_template_547.json : 0.9707602339181287\n",
            "generated_template_565.json : 0.9226190476190477\n",
            "generated_template_575.json : 0.926605504587156\n",
            "generated_template_579.json : 0.9368029739776952\n",
            "generated_template_58.json : 0.8829113924050633\n",
            "generated_template_581.json : 0.9212827988338192\n",
            "generated_template_582.json : 0.9113573407202216\n",
            "generated_template_602.json : 0.9504950495049505\n",
            "generated_template_609.json : 0.9301587301587302\n",
            "generated_template_61.json : 0.9101123595505618\n",
            "generated_template_616.json : 0.9123867069486404\n",
            "generated_template_642.json : 0.90625\n",
            "generated_template_643.json : 0.8410596026490066\n",
            "generated_template_649.json : 0.9225806451612903\n",
            "generated_template_673.json : 0.8613569321533923\n",
            "generated_template_684.json : 0.9475218658892128\n",
            "generated_template_694.json : 0.8587257617728532\n",
            "generated_template_704.json : 0.8029850746268656\n",
            "generated_template_708.json : 0.8832807570977919\n",
            "generated_template_724.json : 0.8901734104046243\n",
            "generated_template_73.json : 0.8856209150326797\n",
            "generated_template_731.json : 0.8681948424068768\n",
            "generated_template_755.json : 0.8724637681159421\n",
            "generated_template_764.json : 0.9339080459770115\n",
            "generated_template_773.json : 0.9415384615384615\n",
            "generated_template_776.json : 0.9517684887459807\n",
            "generated_template_777.json : 0.8881987577639752\n",
            "generated_template_79.json : 0.9359756097560976\n",
            "generated_template_8.json : 0.9343283582089552\n",
            "generated_template_807.json : 0.9485714285714286\n",
            "generated_template_812.json : 0.8970588235294118\n",
            "generated_template_814.json : 0.9118541033434651\n",
            "generated_template_826.json : 0.8681318681318682\n",
            "generated_template_831.json : 0.8837209302325582\n",
            "generated_template_88.json : 0.8769230769230769\n",
            "generated_template_93.json : 0.9392265193370166\n",
            "90.99179637326725\n",
            "100\n",
            "Average Score:  0.9099179637326725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "nI2II4iMWbwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel, DonutProcessor\n",
        "model = VisionEncoderDecoderModel.from_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\checkpoint-2200\")\n",
        "#processor = DonutProcessor.from_pretrained(r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\checkpoint-2200\")\n"
      ],
      "metadata": {
        "id": "VzHMtbDCbX-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "iGuzUjxJxY90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "imag_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\\Images\\generated_template_8.jpg\"\n",
        "img = Image.open(imag_path)\n",
        "\n",
        "inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**inputs, max_length = 1024, return_dict_in_generate=True, output_hidden_states=True)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\Layers output\\Image1\\Encoder\"\n",
        "save_heatmaps(outputs, folder_path)\n",
        "\n",
        "\n",
        "folder_path1 = r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\Layers output\\Image1\\Decoder\"\n",
        "save_Dheatmaps(outputs, folder_path1)\n"
      ],
      "metadata": {
        "id": "eQn_vkRnbX4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566ccafd-59c4-4863-9e71-251dd92ec48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most repeated number (mode): -0.4194834530353546, Count: 275668\n",
            "Most repeated number (mode): 4.030324935913086, Count: 22163\n",
            "Most repeated number (mode): -2.0944454669952393, Count: 2811\n",
            "Most repeated number (mode): -0.23195835947990417, Count: 5\n",
            "Most repeated number (mode): -1.2513415813446045, Count: 4\n",
            "Most repeated number (mode): nan, Count: 0.0\n",
            "Most repeated number (mode): nan, Count: 0.0\n",
            "Most repeated number (mode): nan, Count: 0.0\n",
            "Most repeated number (mode): nan, Count: 0.0\n",
            "Most repeated number (mode): nan, Count: 0.0\n",
            "Heatmaps saved in E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\Layers output\\Image1\\Decoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "imag_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\\Images\\generated_template_44.jpg\"\n",
        "img = Image.open(imag_path)\n",
        "\n",
        "inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**inputs, max_length = 1024, return_dict_in_generate=True, output_hidden_states=True)\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\Layers output\\Image2\\Encoder\"\n",
        "save_heatmaps(outputs, folder_path)\n",
        "\n",
        "\n",
        "folder_path1 = r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\Layers output\\Image2\\Decoder\"\n",
        "save_Dheatmaps(outputs, folder_path1)\n"
      ],
      "metadata": {
        "id": "xN_1SdrybX1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "imag_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\\Images\\generated_template_93.jpg\"\n",
        "img = Image.open(imag_path)\n",
        "\n",
        "inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "outputs = model.generate(**inputs, max_length = 1024, return_dict_in_generate=True, output_hidden_states=True)\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\Layers output\\Image3\\Encoder\"\n",
        "save_heatmaps(outputs, folder_path)\n",
        "\n",
        "\n",
        "folder_path1 = r\"E:\\Abdul_Muqtadir\\Thesis\\DONUT_MathOCR\\Layers output\\Image3\\Decoder\"\n",
        "save_Dheatmaps(outputs, folder_path1)"
      ],
      "metadata": {
        "id": "YLTF4ypibXND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def find_mode(array):\n",
        "    # Flatten the array if it's multidimensional\n",
        "    flattened_array = array.flatten()\n",
        "\n",
        "    # Calculate the mode\n",
        "    mode_result = stats.mode(flattened_array, keepdims=True)\n",
        "\n",
        "    # Extract mode value and count, handling scalars and arrays\n",
        "    mode_value = mode_result.mode.item()  # Convert to scalar\n",
        "    count = mode_result.count.item()      # Convert to scalar\n",
        "\n",
        "    print(f\"Most repeated number (mode): {mode_value}, Count: {count}\")\n"
      ],
      "metadata": {
        "id": "PGBEI58J5e03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.ndimage import zoom\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "def save_heatmaps(outputs, folder_path):\n",
        "\n",
        "    # Ensure the folder exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    for i in range(0, 5):\n",
        "        # Extract the hidden state, move to CPU, and convert to NumPy array\n",
        "        array = outputs['encoder_hidden_states'][i][0].cpu().numpy()\n",
        "\n",
        "        find_mode(array)\n",
        "\n",
        "        # Reduce its size by 50%\n",
        "        array_resized = zoom(array, 0.3)  # Reduces both width and height by 50%\n",
        "\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        sns.heatmap(array_resized, cmap='viridis')\n",
        "\n",
        "        # Increase font size on x and y axes\n",
        "        plt.xticks(fontsize=12)\n",
        "        plt.yticks(fontsize=12)\n",
        "\n",
        "        plt.title(f\"Heatmap for {i+1} number Hidden state of Encoder\", fontsize=10)\n",
        "\n",
        "        # Save the heatmap without displaying it\n",
        "        file_path = os.path.join(folder_path, f\"encoder_hidden_state_{i+1}.png\")\n",
        "        plt.savefig(file_path)\n",
        "        plt.close()  # Close the plot to save memory\n",
        "\n",
        "\n",
        "\n",
        "# Heatmap for Decoder' Hidden states\n",
        "\n",
        "def save_Dheatmaps(outputs, folder_path):\n",
        "\n",
        "    # Ensure the folder exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    for i in range(0, 5):\n",
        "        array = outputs['decoder_hidden_states'][45][i][0].cpu().numpy()\n",
        "        array_resized = zoom(array, 0.3)  # Reduces both width and height by 50%\n",
        "        find_mode(array_resized)\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        sns.heatmap(array, cmap='viridis')\n",
        "        plt.title(f\"Heatmap for {i+1} number Hidden state of Decoder\", fontsize=10)\n",
        "\n",
        "        # Increase font size on x and y\n",
        "        plt.xticks(fontsize=12)\n",
        "        plt.yticks(fontsize=12)\n",
        "\n",
        "        # Save the heatmap without displaying it\n",
        "        file_path = os.path.join(folder_path, f\"decoder_hidden_state_{i+1}.png\")\n",
        "        plt.savefig(file_path)\n",
        "        plt.close()  # Close the figure to avoid displaying it\n",
        "\n",
        "    print(f\"Heatmaps saved in {folder_path}\")\n"
      ],
      "metadata": {
        "id": "zAwbxBBGbXJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSW3CraXbXGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1knWyC1MbXC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXNIgxv-bW_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "# import shutil\n",
        "# import time\n",
        "\n",
        "# # Define the source directory containing JSON files\n",
        "# source_dir = r'E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex'  # Replace with your source folder path\n",
        "# # Define the destination directory\n",
        "# destination_dir = r'E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex\\Jsons'  # Replace with your destination folder path\n",
        "\n",
        "# def get_folder_name(length):\n",
        "#     if length < 30:  # You can adjust this threshold as needed\n",
        "#         return 'short_sequences'\n",
        "#     else:\n",
        "#         return 'long_sequences'\n",
        "\n",
        "# # Create destination folders if they don't exist\n",
        "# short_sequences_dir = os.path.join(destination_dir, 'short_sequences')\n",
        "# long_sequences_dir = os.path.join(destination_dir, 'long_sequences')\n",
        "\n",
        "# os.makedirs(short_sequences_dir, exist_ok=True)\n",
        "# os.makedirs(long_sequences_dir, exist_ok=True)\n",
        "\n",
        "# # Loop through each file in the source directory\n",
        "# for filename in os.listdir(source_dir):\n",
        "#     if filename.lower().endswith('.json'):\n",
        "#         json_path = os.path.join(source_dir, filename)\n",
        "\n",
        "#         # Read the JSON file\n",
        "#         with open(json_path, 'r') as json_file:\n",
        "#             try:\n",
        "#                 # Load the JSON data\n",
        "#                 data = json.load(json_file)\n",
        "\n",
        "#                 # Ensure that 'uuid' is present and is a string\n",
        "#                 uuid = data.get('uuid', '')\n",
        "\n",
        "#                 # Calculate the sequence length\n",
        "#                 seq_length = len(uuid)\n",
        "#                 folder_name = get_folder_name(seq_length)\n",
        "\n",
        "#                 # Attempt to move the JSON file to the respective folder\n",
        "#                 moved = False\n",
        "#                 attempts = 0\n",
        "#                 while not moved and attempts < 3:  # Retry up to 3 times\n",
        "#                     try:\n",
        "#                         shutil.move(json_path, os.path.join(destination_dir, folder_name, filename))\n",
        "#                         print(f'Moved: {filename} to {folder_name}')\n",
        "#                         moved = True\n",
        "#                     except PermissionError:  # Catch the specific error\n",
        "#                         print(f'File {filename} is in use, retrying...')\n",
        "#                         attempts += 1\n",
        "#                         time.sleep(1)  # Wait for 1 second before retrying\n",
        "\n",
        "#             except json.JSONDecodeError:\n",
        "#                 print(f'Error decoding JSON from file: {filename}')\n",
        "#             except Exception as e:\n",
        "#                 print(f'An error occurred with file {filename}: {e}')\n",
        "\n",
        "# print('JSON separation completed.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "shGaGNUiWgds",
        "outputId": "eeb9a0c8-a69a-4bff-a7df-44b0504c99f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 000000.target.json is in use, retrying...\n",
            "File 000000.target.json is in use, retrying...\n",
            "File 000000.target.json is in use, retrying...\n",
            "File 000001.target.json is in use, retrying...\n",
            "File 000001.target.json is in use, retrying...\n",
            "File 000001.target.json is in use, retrying...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\shutil.py:825\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
            "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'E:\\\\Abdul_Muqtadir\\\\Thesis\\\\Dataset\\\\Iam2Latex\\\\000001.target.json' -> 'E:\\\\Abdul_Muqtadir\\\\Thesis\\\\Dataset\\\\Iam2Latex\\\\Jsons\\\\long_sequences\\\\000001.target.json'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[66], line 47\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mC:\\Anaconda3\\envs\\newdonut\\Lib\\shutil.py:846\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    845\u001b[0m         copy_function(src, real_dst)\n\u001b[1;32m--> 846\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
            "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'E:\\\\Abdul_Muqtadir\\\\Thesis\\\\Dataset\\\\Iam2Latex\\\\000001.target.json'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[66], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is in use, retrying...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m             attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 53\u001b[0m             \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for 1 second before retrying\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError decoding JSON from file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Paths to the source and destination folders\n",
        "source_folder = r'E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final'  # Replace with the path to Folder A\n",
        "destination_folder = r'E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E'  # Replace with the path to Folder B\n",
        "\n",
        "# Function to create destination path structure and convert JSON format\n",
        "def convert_json_file(source_file_path, destination_file_path):\n",
        "    # Load the source JSON file\n",
        "    with open(source_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Transform the JSON format\n",
        "    converted_data = {}\n",
        "    for i, patch in enumerate(data.get('patches', [])):\n",
        "        latex_key = f'latex_{i + 1}'\n",
        "        converted_data[latex_key] = patch.get('latex_equation', '')\n",
        "\n",
        "    # Save the transformed JSON to the destination path\n",
        "    os.makedirs(os.path.dirname(destination_file_path), exist_ok=True)\n",
        "    with open(destination_file_path, 'w') as f:\n",
        "        json.dump(converted_data, f, indent=4)\n",
        "    print(f\"Converted and saved: {destination_file_path}\")\n",
        "\n",
        "# Walk through the source folder and process each JSON file\n",
        "for root, _, files in os.walk(source_folder):\n",
        "    for file in files:\n",
        "        if file.lower().endswith('.json'):\n",
        "            # Define full paths for source and destination files\n",
        "            source_file_path = os.path.join(root, file)\n",
        "            relative_path = os.path.relpath(source_file_path, source_folder)\n",
        "            destination_file_path = os.path.join(destination_folder, relative_path)\n",
        "\n",
        "            # Convert and save the JSON file\n",
        "            convert_json_file(source_file_path, destination_file_path)\n",
        "\n",
        "print(\"All JSON files have been converted and saved in Folder B.\")\n"
      ],
      "metadata": {
        "id": "cVzMiP7vyNzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea4678e-42a1-43fe-e373-e2f1ab9bcdb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_1.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_10.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_11.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_12.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_13.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_14.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_15.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_16.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_17.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_18.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_19.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_2.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_20.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_21.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_22.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_23.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_24.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_25.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_26.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_27.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_3.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_4.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_5.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_6.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_7.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_8.json\n",
            "Converted and saved: E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Iam2Latex_Final_Test_Dataset\\Generated_final/E2E\\generated_template_9.json\n",
            "All JSON files have been converted and saved in Folder B.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Path to folder A\n",
        "folder_path = r\"E:\\Abdul_Muqtadir\\Thesis\\Dataset\\Test_Iamlatex2\\test\"\n",
        "\n",
        "# Initialize categories\n",
        "categories = {\n",
        "    \"square_root\": [],\n",
        "    \"algebra\": [],\n",
        "    \"trigonometry\": [],\n",
        "    \"exponential_log\": []\n",
        "}\n",
        "\n",
        "# Regular expressions for LaTeX patterns\n",
        "patterns = {\n",
        "    \"square_root\": r\"\\\\sqrt\",\n",
        "    \"algebra\": r\"\\\\frac|[a-zA-Z]+\\s*=\\s*[a-zA-Z0-9\\+\\-\\*/\\(\\)\\^ ]+\",\n",
        "    \"trigonometry\": r\"\\\\sin|\\\\cos|\\\\tan|\\\\csc|\\\\sec|\\\\cot\",\n",
        "    \"exponential_log\": r\"\\\\exp|\\\\log\"\n",
        "}\n",
        "\n",
        "# Process each JSON file in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".json\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        with open(file_path, \"r\") as file:\n",
        "            try:\n",
        "                data = json.load(file)\n",
        "                matched = False\n",
        "\n",
        "                # Check LaTeX content against each category\n",
        "                for key, value in data.items():\n",
        "                    for category, pattern in patterns.items():\n",
        "                        if re.search(pattern, value):\n",
        "                            categories[category].append(filename)\n",
        "                            matched = True\n",
        "                            break\n",
        "                    if matched:\n",
        "                        break\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error decoding {filename}, skipping.\")\n",
        "\n",
        "# Print the grouped filenames\n",
        "for category, files in categories.items():\n",
        "    print(f\"\\n{category.upper()}:\")\n",
        "    for file in set(files):  # Avoid duplicate entries\n",
        "        print(file)\n"
      ],
      "metadata": {
        "id": "SDLn0IgIDkdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3296885c-e313-4fa8-d0b0-9e05091eee54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SQUARE_ROOT:\n",
            "generated_template_243.json\n",
            "generated_template_731.json\n",
            "generated_template_755.json\n",
            "generated_template_545.json\n",
            "generated_template_544.json\n",
            "generated_template_158.json\n",
            "generated_template_310.json\n",
            "\n",
            "ALGEBRA:\n",
            "generated_template_8.json\n",
            "generated_template_88.json\n",
            "generated_template_281.json\n",
            "generated_template_519.json\n",
            "generated_template_477.json\n",
            "generated_template_724.json\n",
            "generated_template_540.json\n",
            "generated_template_169.json\n",
            "generated_template_236.json\n",
            "generated_template_33.json\n",
            "generated_template_428.json\n",
            "generated_template_508.json\n",
            "generated_template_61.json\n",
            "generated_template_17.json\n",
            "generated_template_389.json\n",
            "generated_template_579.json\n",
            "generated_template_403.json\n",
            "generated_template_43.json\n",
            "generated_template_269.json\n",
            "generated_template_547.json\n",
            "generated_template_616.json\n",
            "generated_template_807.json\n",
            "generated_template_565.json\n",
            "generated_template_58.json\n",
            "generated_template_487.json\n",
            "generated_template_377.json\n",
            "generated_template_704.json\n",
            "generated_template_378.json\n",
            "generated_template_512.json\n",
            "generated_template_812.json\n",
            "generated_template_28.json\n",
            "generated_template_383.json\n",
            "generated_template_412.json\n",
            "generated_template_643.json\n",
            "generated_template_267.json\n",
            "generated_template_40.json\n",
            "generated_template_268.json\n",
            "generated_template_776.json\n",
            "generated_template_582.json\n",
            "generated_template_93.json\n",
            "generated_template_26.json\n",
            "generated_template_525.json\n",
            "generated_template_49.json\n",
            "generated_template_395.json\n",
            "generated_template_303.json\n",
            "generated_template_238.json\n",
            "generated_template_131.json\n",
            "generated_template_528.json\n",
            "generated_template_162.json\n",
            "generated_template_814.json\n",
            "generated_template_609.json\n",
            "generated_template_642.json\n",
            "generated_template_694.json\n",
            "generated_template_188.json\n",
            "generated_template_438.json\n",
            "generated_template_346.json\n",
            "generated_template_575.json\n",
            "generated_template_174.json\n",
            "generated_template_179.json\n",
            "generated_template_418.json\n",
            "generated_template_502.json\n",
            "generated_template_764.json\n",
            "generated_template_305.json\n",
            "generated_template_602.json\n",
            "generated_template_422.json\n",
            "generated_template_708.json\n",
            "generated_template_155.json\n",
            "generated_template_831.json\n",
            "generated_template_73.json\n",
            "generated_template_409.json\n",
            "generated_template_826.json\n",
            "generated_template_282.json\n",
            "generated_template_79.json\n",
            "generated_template_129.json\n",
            "generated_template_777.json\n",
            "generated_template_498.json\n",
            "generated_template_16.json\n",
            "generated_template_221.json\n",
            "generated_template_244.json\n",
            "generated_template_44.json\n",
            "generated_template_349.json\n",
            "generated_template_649.json\n",
            "generated_template_394.json\n",
            "generated_template_581.json\n",
            "generated_template_684.json\n",
            "generated_template_106.json\n",
            "generated_template_25.json\n",
            "generated_template_341.json\n",
            "generated_template_673.json\n",
            "generated_template_773.json\n",
            "generated_template_157.json\n",
            "\n",
            "TRIGONOMETRY:\n",
            "generated_template_356.json\n",
            "generated_template_365.json\n",
            "\n",
            "EXPONENTIAL_LOG:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rQItpvgNyUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}